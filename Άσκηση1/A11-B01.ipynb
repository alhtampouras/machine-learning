{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A11-B01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "id": "BCg00lZACdry",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Α. Στοιχεία Ομάδας\n",
        "***\n",
        "\n",
        "|Όνομα|ΑΜ|Ομάδα|\n",
        "|-|-|-|\n",
        "|Λιάτσος Γεώργιος-Ελευθέριος|03114026|Α11|\n",
        "|Κουτρούλης Σπυραντώνης     |03114864|Α11|"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "gd8SH8deJKzA",
        "colab_type": "code",
        "trusted": true,
        "outputId": "9dc3e187-2809-4506-8224-1a57fa7b2e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade scikit-learn\n",
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade scipy\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (18.1)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.14.6)\n",
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/d8/feeb346d41f181e83fba45224ab14a8d8af019b48af742e047f3845d8cff/pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 8.9MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 0.22.0\n",
            "    Uninstalling pandas-0.22.0:\n",
            "      Successfully uninstalled pandas-0.22.0\n",
            "Successfully installed pandas-0.23.4\n",
            "Collecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 2.7MB/s \n",
            "\u001b[31mthinc 6.12.1 has requirement msgpack<0.6.0,>=0.5.6, but you'll have msgpack 0.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed numpy-1.15.4\n",
            "Requirement already up-to-date: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.15.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A7o0LHrACdr4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "# Β. Εισαγωγή του dataset\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "tdpDno1oCdr6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### B1. Παρουσίαση του dataset\n",
        "Τα δεδομένα δημιουργούνται από το MC (Monte Carlo program) για την προσομοίωση της εγγραφής σωματιδίων γάμμα  υψηλής ενέργειας σε ένα γειωμένο γήινο τηλεσκόπιο Cherenkov με βάση τη γη, χρησιμοποιώντας την τεχνική απεικόνισης\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "nD0yfQLkCdr6",
        "colab_type": "code",
        "outputId": "ef419102-3175-4b58-af91-7d8d24dce32d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "x = pd.read_table(\"http://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data\",header=None,sep=',')\n",
        "print(x.shape)\n",
        "x.head()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19020, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.7967</td>\n",
              "      <td>16.0021</td>\n",
              "      <td>2.6449</td>\n",
              "      <td>0.3918</td>\n",
              "      <td>0.1982</td>\n",
              "      <td>27.7004</td>\n",
              "      <td>22.0110</td>\n",
              "      <td>-8.2027</td>\n",
              "      <td>40.0920</td>\n",
              "      <td>81.8828</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31.6036</td>\n",
              "      <td>11.7235</td>\n",
              "      <td>2.5185</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.3773</td>\n",
              "      <td>26.2722</td>\n",
              "      <td>23.8238</td>\n",
              "      <td>-9.9574</td>\n",
              "      <td>6.3609</td>\n",
              "      <td>205.2610</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>162.0520</td>\n",
              "      <td>136.0310</td>\n",
              "      <td>4.0612</td>\n",
              "      <td>0.0374</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>116.7410</td>\n",
              "      <td>-64.8580</td>\n",
              "      <td>-45.2160</td>\n",
              "      <td>76.9600</td>\n",
              "      <td>256.7880</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.8172</td>\n",
              "      <td>9.5728</td>\n",
              "      <td>2.3385</td>\n",
              "      <td>0.6147</td>\n",
              "      <td>0.3922</td>\n",
              "      <td>27.2107</td>\n",
              "      <td>-6.4633</td>\n",
              "      <td>-7.1513</td>\n",
              "      <td>10.4490</td>\n",
              "      <td>116.7370</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75.1362</td>\n",
              "      <td>30.9205</td>\n",
              "      <td>3.1611</td>\n",
              "      <td>0.3168</td>\n",
              "      <td>0.1832</td>\n",
              "      <td>-5.5277</td>\n",
              "      <td>28.5525</td>\n",
              "      <td>21.8393</td>\n",
              "      <td>4.6480</td>\n",
              "      <td>356.4620</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1       2       3       4         5        6        7   \\\n",
              "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
              "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
              "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
              "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
              "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
              "\n",
              "        8         9  10  \n",
              "0  40.0920   81.8828  g  \n",
              "1   6.3609  205.2610  g  \n",
              "2  76.9600  256.7880  g  \n",
              "3  10.4490  116.7370  g  \n",
              "4   4.6480  356.4620  g  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "OGeElTzaCdsC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### B2. Δείγματα και χαρακτηριστικά \n",
        "\n",
        "Το μέγεθος του dataset το βρήκαμε απο πάνω. Οπότε ο αριθμός των δειγμάτων είναι 19020 και ο αριθμός των χαρακτηριστικών είναι 10 + 1 η κλαση\n",
        "\n",
        "Τα χαρακτηριστικά όπως και το είδος τους αναγράφονται στην κεντρική σελίδα του MAGIC Gamma Telescope Data Set και είναι τα εξής : \n",
        "        1.  fLength:  continuous  # major axis of ellipse [mm]\n",
        "        2.  fWidth:   continuous  # minor axis of ellipse [mm] \n",
        "        3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]\n",
        "        4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]\n",
        "        5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]\n",
        "        6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]\n",
        "        7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm] \n",
        "        8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]\n",
        "        9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]\n",
        "       10.  fDist:    continuous  # distance from origin to center of ellipse [mm]\n",
        "       11.  class:    g,h         # gamma (signal), hadron (background)\n",
        " \n",
        " #### Δεν υπάρχουν μη διατεταγμένα χαρακτηριστικά "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "AhK8x6AdCdsE",
        "colab_type": "code",
        "outputId": "983ef3c3-268f-4f25-cf1c-e280279809d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "attributes = ['fLength','fWidth','fSize','fConc','fConc1','fAsym','fM3Long','fM3Trans','fAlpha','fDist','class']\n",
        "for i in range(0,11):\n",
        "    x.rename(columns = {i:attributes[i]},inplace=True)\n",
        "x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fLength</th>\n",
              "      <th>fWidth</th>\n",
              "      <th>fSize</th>\n",
              "      <th>fConc</th>\n",
              "      <th>fConc1</th>\n",
              "      <th>fAsym</th>\n",
              "      <th>fM3Long</th>\n",
              "      <th>fM3Trans</th>\n",
              "      <th>fAlpha</th>\n",
              "      <th>fDist</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.7967</td>\n",
              "      <td>16.0021</td>\n",
              "      <td>2.6449</td>\n",
              "      <td>0.3918</td>\n",
              "      <td>0.1982</td>\n",
              "      <td>27.7004</td>\n",
              "      <td>22.0110</td>\n",
              "      <td>-8.2027</td>\n",
              "      <td>40.0920</td>\n",
              "      <td>81.8828</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31.6036</td>\n",
              "      <td>11.7235</td>\n",
              "      <td>2.5185</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.3773</td>\n",
              "      <td>26.2722</td>\n",
              "      <td>23.8238</td>\n",
              "      <td>-9.9574</td>\n",
              "      <td>6.3609</td>\n",
              "      <td>205.2610</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>162.0520</td>\n",
              "      <td>136.0310</td>\n",
              "      <td>4.0612</td>\n",
              "      <td>0.0374</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>116.7410</td>\n",
              "      <td>-64.8580</td>\n",
              "      <td>-45.2160</td>\n",
              "      <td>76.9600</td>\n",
              "      <td>256.7880</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.8172</td>\n",
              "      <td>9.5728</td>\n",
              "      <td>2.3385</td>\n",
              "      <td>0.6147</td>\n",
              "      <td>0.3922</td>\n",
              "      <td>27.2107</td>\n",
              "      <td>-6.4633</td>\n",
              "      <td>-7.1513</td>\n",
              "      <td>10.4490</td>\n",
              "      <td>116.7370</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75.1362</td>\n",
              "      <td>30.9205</td>\n",
              "      <td>3.1611</td>\n",
              "      <td>0.3168</td>\n",
              "      <td>0.1832</td>\n",
              "      <td>-5.5277</td>\n",
              "      <td>28.5525</td>\n",
              "      <td>21.8393</td>\n",
              "      <td>4.6480</td>\n",
              "      <td>356.4620</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>51.6240</td>\n",
              "      <td>21.1502</td>\n",
              "      <td>2.9085</td>\n",
              "      <td>0.2420</td>\n",
              "      <td>0.1340</td>\n",
              "      <td>50.8761</td>\n",
              "      <td>43.1887</td>\n",
              "      <td>9.8145</td>\n",
              "      <td>3.6130</td>\n",
              "      <td>238.0980</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>48.2468</td>\n",
              "      <td>17.3565</td>\n",
              "      <td>3.0332</td>\n",
              "      <td>0.2529</td>\n",
              "      <td>0.1515</td>\n",
              "      <td>8.5730</td>\n",
              "      <td>38.0957</td>\n",
              "      <td>10.5868</td>\n",
              "      <td>4.7920</td>\n",
              "      <td>219.0870</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>26.7897</td>\n",
              "      <td>13.7595</td>\n",
              "      <td>2.5521</td>\n",
              "      <td>0.4236</td>\n",
              "      <td>0.2174</td>\n",
              "      <td>29.6339</td>\n",
              "      <td>20.4560</td>\n",
              "      <td>-2.9292</td>\n",
              "      <td>0.8120</td>\n",
              "      <td>237.1340</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>96.2327</td>\n",
              "      <td>46.5165</td>\n",
              "      <td>4.1540</td>\n",
              "      <td>0.0779</td>\n",
              "      <td>0.0390</td>\n",
              "      <td>110.3550</td>\n",
              "      <td>85.0486</td>\n",
              "      <td>43.1844</td>\n",
              "      <td>4.8540</td>\n",
              "      <td>248.2260</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>46.7619</td>\n",
              "      <td>15.1993</td>\n",
              "      <td>2.5786</td>\n",
              "      <td>0.3377</td>\n",
              "      <td>0.1913</td>\n",
              "      <td>24.7548</td>\n",
              "      <td>43.8771</td>\n",
              "      <td>-6.6812</td>\n",
              "      <td>7.8750</td>\n",
              "      <td>102.2510</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>62.7766</td>\n",
              "      <td>29.9104</td>\n",
              "      <td>3.3331</td>\n",
              "      <td>0.2475</td>\n",
              "      <td>0.1261</td>\n",
              "      <td>-33.9065</td>\n",
              "      <td>57.5848</td>\n",
              "      <td>23.7710</td>\n",
              "      <td>9.9144</td>\n",
              "      <td>323.0940</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>18.8562</td>\n",
              "      <td>16.4600</td>\n",
              "      <td>2.4385</td>\n",
              "      <td>0.5282</td>\n",
              "      <td>0.2933</td>\n",
              "      <td>25.1269</td>\n",
              "      <td>-6.5401</td>\n",
              "      <td>-16.9327</td>\n",
              "      <td>11.4610</td>\n",
              "      <td>162.8480</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>45.6321</td>\n",
              "      <td>22.7100</td>\n",
              "      <td>3.0441</td>\n",
              "      <td>0.2213</td>\n",
              "      <td>0.1215</td>\n",
              "      <td>-18.3986</td>\n",
              "      <td>-20.6427</td>\n",
              "      <td>-14.3164</td>\n",
              "      <td>0.3822</td>\n",
              "      <td>178.2550</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>33.1818</td>\n",
              "      <td>12.4655</td>\n",
              "      <td>2.4955</td>\n",
              "      <td>0.4696</td>\n",
              "      <td>0.2412</td>\n",
              "      <td>-17.0341</td>\n",
              "      <td>-22.0762</td>\n",
              "      <td>-8.1803</td>\n",
              "      <td>41.9290</td>\n",
              "      <td>41.3816</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>60.4580</td>\n",
              "      <td>33.1061</td>\n",
              "      <td>3.1944</td>\n",
              "      <td>0.4679</td>\n",
              "      <td>0.2464</td>\n",
              "      <td>14.3000</td>\n",
              "      <td>-33.8765</td>\n",
              "      <td>28.8315</td>\n",
              "      <td>8.2920</td>\n",
              "      <td>372.5680</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>29.4741</td>\n",
              "      <td>22.4581</td>\n",
              "      <td>2.6258</td>\n",
              "      <td>0.3077</td>\n",
              "      <td>0.1740</td>\n",
              "      <td>18.1242</td>\n",
              "      <td>22.7035</td>\n",
              "      <td>13.1673</td>\n",
              "      <td>48.0364</td>\n",
              "      <td>214.1260</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>36.1741</td>\n",
              "      <td>17.6865</td>\n",
              "      <td>2.9460</td>\n",
              "      <td>0.2865</td>\n",
              "      <td>0.1591</td>\n",
              "      <td>-4.7746</td>\n",
              "      <td>-18.9697</td>\n",
              "      <td>11.3256</td>\n",
              "      <td>0.2540</td>\n",
              "      <td>191.4550</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>46.2915</td>\n",
              "      <td>16.0328</td>\n",
              "      <td>2.7756</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1920</td>\n",
              "      <td>49.9706</td>\n",
              "      <td>33.3653</td>\n",
              "      <td>-12.7979</td>\n",
              "      <td>38.7070</td>\n",
              "      <td>75.5234</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>46.0588</td>\n",
              "      <td>18.7870</td>\n",
              "      <td>3.2217</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.1504</td>\n",
              "      <td>49.2704</td>\n",
              "      <td>34.1066</td>\n",
              "      <td>10.7955</td>\n",
              "      <td>8.6860</td>\n",
              "      <td>180.7830</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>44.7394</td>\n",
              "      <td>15.6364</td>\n",
              "      <td>2.6380</td>\n",
              "      <td>0.3107</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>14.0430</td>\n",
              "      <td>37.2246</td>\n",
              "      <td>12.4183</td>\n",
              "      <td>3.2510</td>\n",
              "      <td>221.8060</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>91.6423</td>\n",
              "      <td>71.8818</td>\n",
              "      <td>3.8484</td>\n",
              "      <td>0.0780</td>\n",
              "      <td>0.0430</td>\n",
              "      <td>-56.7107</td>\n",
              "      <td>72.3016</td>\n",
              "      <td>60.0190</td>\n",
              "      <td>16.6220</td>\n",
              "      <td>285.4140</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>86.0486</td>\n",
              "      <td>21.8287</td>\n",
              "      <td>3.3587</td>\n",
              "      <td>0.2369</td>\n",
              "      <td>0.1662</td>\n",
              "      <td>-58.7854</td>\n",
              "      <td>57.8212</td>\n",
              "      <td>-18.8093</td>\n",
              "      <td>2.0050</td>\n",
              "      <td>302.5530</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>90.5299</td>\n",
              "      <td>17.8721</td>\n",
              "      <td>3.0330</td>\n",
              "      <td>0.2122</td>\n",
              "      <td>0.1080</td>\n",
              "      <td>-57.4170</td>\n",
              "      <td>84.6189</td>\n",
              "      <td>14.9662</td>\n",
              "      <td>2.0390</td>\n",
              "      <td>272.0380</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>20.3836</td>\n",
              "      <td>9.0462</td>\n",
              "      <td>2.3365</td>\n",
              "      <td>0.6359</td>\n",
              "      <td>0.3894</td>\n",
              "      <td>22.2700</td>\n",
              "      <td>12.9487</td>\n",
              "      <td>-2.0403</td>\n",
              "      <td>43.0032</td>\n",
              "      <td>66.1667</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>87.2384</td>\n",
              "      <td>27.9350</td>\n",
              "      <td>2.8848</td>\n",
              "      <td>0.3155</td>\n",
              "      <td>0.1806</td>\n",
              "      <td>-18.2102</td>\n",
              "      <td>66.6867</td>\n",
              "      <td>-11.3438</td>\n",
              "      <td>4.4265</td>\n",
              "      <td>342.5040</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>107.3380</td>\n",
              "      <td>29.1356</td>\n",
              "      <td>3.5265</td>\n",
              "      <td>0.1315</td>\n",
              "      <td>0.0683</td>\n",
              "      <td>-47.1175</td>\n",
              "      <td>89.5136</td>\n",
              "      <td>-20.0479</td>\n",
              "      <td>3.3120</td>\n",
              "      <td>293.7810</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27.2304</td>\n",
              "      <td>19.2817</td>\n",
              "      <td>2.6375</td>\n",
              "      <td>0.3710</td>\n",
              "      <td>0.2039</td>\n",
              "      <td>23.0406</td>\n",
              "      <td>23.3428</td>\n",
              "      <td>9.7216</td>\n",
              "      <td>77.5379</td>\n",
              "      <td>104.2830</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>26.7065</td>\n",
              "      <td>18.9070</td>\n",
              "      <td>2.6781</td>\n",
              "      <td>0.4281</td>\n",
              "      <td>0.2214</td>\n",
              "      <td>9.1616</td>\n",
              "      <td>18.6858</td>\n",
              "      <td>-11.6888</td>\n",
              "      <td>26.8810</td>\n",
              "      <td>63.7637</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>23.5647</td>\n",
              "      <td>9.9926</td>\n",
              "      <td>2.2095</td>\n",
              "      <td>0.5679</td>\n",
              "      <td>0.3364</td>\n",
              "      <td>30.0056</td>\n",
              "      <td>-13.8665</td>\n",
              "      <td>-8.2600</td>\n",
              "      <td>26.5328</td>\n",
              "      <td>185.1890</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>34.7486</td>\n",
              "      <td>19.2286</td>\n",
              "      <td>2.5629</td>\n",
              "      <td>0.3666</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>30.3637</td>\n",
              "      <td>-16.3092</td>\n",
              "      <td>14.3186</td>\n",
              "      <td>1.5210</td>\n",
              "      <td>109.4450</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18990</th>\n",
              "      <td>26.0277</td>\n",
              "      <td>7.4010</td>\n",
              "      <td>2.4223</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.3791</td>\n",
              "      <td>-27.8670</td>\n",
              "      <td>14.0382</td>\n",
              "      <td>-12.9981</td>\n",
              "      <td>64.7583</td>\n",
              "      <td>186.2433</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18991</th>\n",
              "      <td>32.1547</td>\n",
              "      <td>12.5410</td>\n",
              "      <td>2.7593</td>\n",
              "      <td>0.4317</td>\n",
              "      <td>0.2167</td>\n",
              "      <td>31.6221</td>\n",
              "      <td>24.5785</td>\n",
              "      <td>-9.6861</td>\n",
              "      <td>35.1840</td>\n",
              "      <td>192.5870</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18992</th>\n",
              "      <td>169.0402</td>\n",
              "      <td>35.3614</td>\n",
              "      <td>3.2894</td>\n",
              "      <td>0.3349</td>\n",
              "      <td>0.1986</td>\n",
              "      <td>-162.2329</td>\n",
              "      <td>70.4636</td>\n",
              "      <td>-9.7764</td>\n",
              "      <td>48.5542</td>\n",
              "      <td>326.2363</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18993</th>\n",
              "      <td>18.8377</td>\n",
              "      <td>8.8786</td>\n",
              "      <td>2.5617</td>\n",
              "      <td>0.6039</td>\n",
              "      <td>0.3234</td>\n",
              "      <td>0.4589</td>\n",
              "      <td>15.5433</td>\n",
              "      <td>-8.4175</td>\n",
              "      <td>31.5080</td>\n",
              "      <td>164.8029</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18994</th>\n",
              "      <td>195.2309</td>\n",
              "      <td>67.0206</td>\n",
              "      <td>3.7669</td>\n",
              "      <td>0.1195</td>\n",
              "      <td>0.0677</td>\n",
              "      <td>-119.1863</td>\n",
              "      <td>-155.8811</td>\n",
              "      <td>-40.6133</td>\n",
              "      <td>1.9242</td>\n",
              "      <td>213.1906</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18995</th>\n",
              "      <td>67.7139</td>\n",
              "      <td>28.5831</td>\n",
              "      <td>3.2384</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.1106</td>\n",
              "      <td>-133.6450</td>\n",
              "      <td>63.1391</td>\n",
              "      <td>-16.6379</td>\n",
              "      <td>47.9790</td>\n",
              "      <td>251.9930</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18996</th>\n",
              "      <td>29.8353</td>\n",
              "      <td>11.3519</td>\n",
              "      <td>2.4449</td>\n",
              "      <td>0.4890</td>\n",
              "      <td>0.2948</td>\n",
              "      <td>9.9236</td>\n",
              "      <td>-9.0429</td>\n",
              "      <td>16.2790</td>\n",
              "      <td>17.1944</td>\n",
              "      <td>230.5486</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18997</th>\n",
              "      <td>18.0124</td>\n",
              "      <td>10.6746</td>\n",
              "      <td>2.5694</td>\n",
              "      <td>0.5768</td>\n",
              "      <td>0.2951</td>\n",
              "      <td>-23.3968</td>\n",
              "      <td>-9.2150</td>\n",
              "      <td>4.7010</td>\n",
              "      <td>52.4630</td>\n",
              "      <td>172.5960</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18998</th>\n",
              "      <td>207.2530</td>\n",
              "      <td>75.8327</td>\n",
              "      <td>4.1476</td>\n",
              "      <td>0.0739</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>-242.4960</td>\n",
              "      <td>-180.0290</td>\n",
              "      <td>-57.8600</td>\n",
              "      <td>74.5740</td>\n",
              "      <td>259.3160</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18999</th>\n",
              "      <td>172.2442</td>\n",
              "      <td>20.1926</td>\n",
              "      <td>2.9009</td>\n",
              "      <td>0.2887</td>\n",
              "      <td>0.1940</td>\n",
              "      <td>124.5990</td>\n",
              "      <td>112.9452</td>\n",
              "      <td>-21.4436</td>\n",
              "      <td>28.9553</td>\n",
              "      <td>210.8496</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19000</th>\n",
              "      <td>69.3556</td>\n",
              "      <td>31.9822</td>\n",
              "      <td>3.2231</td>\n",
              "      <td>0.3093</td>\n",
              "      <td>0.1744</td>\n",
              "      <td>-52.6569</td>\n",
              "      <td>-42.0622</td>\n",
              "      <td>6.3984</td>\n",
              "      <td>7.6304</td>\n",
              "      <td>289.2860</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19001</th>\n",
              "      <td>57.1905</td>\n",
              "      <td>35.5095</td>\n",
              "      <td>2.7177</td>\n",
              "      <td>0.2337</td>\n",
              "      <td>0.1197</td>\n",
              "      <td>-48.5112</td>\n",
              "      <td>-54.2835</td>\n",
              "      <td>32.3612</td>\n",
              "      <td>44.7320</td>\n",
              "      <td>102.9950</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19002</th>\n",
              "      <td>110.7140</td>\n",
              "      <td>26.8312</td>\n",
              "      <td>3.2212</td>\n",
              "      <td>0.1856</td>\n",
              "      <td>0.1247</td>\n",
              "      <td>-158.0625</td>\n",
              "      <td>73.2259</td>\n",
              "      <td>21.2864</td>\n",
              "      <td>9.3725</td>\n",
              "      <td>281.8795</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19003</th>\n",
              "      <td>21.5189</td>\n",
              "      <td>15.4205</td>\n",
              "      <td>2.7328</td>\n",
              "      <td>0.5587</td>\n",
              "      <td>0.3117</td>\n",
              "      <td>-7.3668</td>\n",
              "      <td>9.2409</td>\n",
              "      <td>17.1609</td>\n",
              "      <td>80.4307</td>\n",
              "      <td>223.9730</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19004</th>\n",
              "      <td>23.4293</td>\n",
              "      <td>11.3673</td>\n",
              "      <td>2.7001</td>\n",
              "      <td>0.3842</td>\n",
              "      <td>0.1890</td>\n",
              "      <td>-26.3784</td>\n",
              "      <td>-14.5363</td>\n",
              "      <td>15.6128</td>\n",
              "      <td>88.3032</td>\n",
              "      <td>269.0718</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19005</th>\n",
              "      <td>23.8277</td>\n",
              "      <td>11.8989</td>\n",
              "      <td>2.4393</td>\n",
              "      <td>0.4655</td>\n",
              "      <td>0.2891</td>\n",
              "      <td>11.1013</td>\n",
              "      <td>11.5776</td>\n",
              "      <td>6.8613</td>\n",
              "      <td>35.3166</td>\n",
              "      <td>152.0720</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19006</th>\n",
              "      <td>32.1454</td>\n",
              "      <td>13.8296</td>\n",
              "      <td>2.4844</td>\n",
              "      <td>0.5182</td>\n",
              "      <td>0.2761</td>\n",
              "      <td>-36.0633</td>\n",
              "      <td>-15.9648</td>\n",
              "      <td>-12.2698</td>\n",
              "      <td>47.3704</td>\n",
              "      <td>246.0565</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19007</th>\n",
              "      <td>115.2640</td>\n",
              "      <td>14.0075</td>\n",
              "      <td>2.8540</td>\n",
              "      <td>0.7544</td>\n",
              "      <td>0.4136</td>\n",
              "      <td>-88.2076</td>\n",
              "      <td>-117.4860</td>\n",
              "      <td>8.4777</td>\n",
              "      <td>28.0100</td>\n",
              "      <td>336.9910</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19008</th>\n",
              "      <td>133.4950</td>\n",
              "      <td>40.1631</td>\n",
              "      <td>3.3050</td>\n",
              "      <td>0.1169</td>\n",
              "      <td>0.0602</td>\n",
              "      <td>84.1711</td>\n",
              "      <td>-81.3323</td>\n",
              "      <td>-31.0503</td>\n",
              "      <td>28.1458</td>\n",
              "      <td>319.3730</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19009</th>\n",
              "      <td>39.5223</td>\n",
              "      <td>18.6327</td>\n",
              "      <td>2.8341</td>\n",
              "      <td>0.2462</td>\n",
              "      <td>0.1414</td>\n",
              "      <td>24.1819</td>\n",
              "      <td>23.2190</td>\n",
              "      <td>-12.9245</td>\n",
              "      <td>46.2680</td>\n",
              "      <td>187.0970</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19010</th>\n",
              "      <td>32.4902</td>\n",
              "      <td>10.6723</td>\n",
              "      <td>2.4742</td>\n",
              "      <td>0.4664</td>\n",
              "      <td>0.2735</td>\n",
              "      <td>-27.0097</td>\n",
              "      <td>-21.1687</td>\n",
              "      <td>8.4813</td>\n",
              "      <td>69.1730</td>\n",
              "      <td>120.6680</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19011</th>\n",
              "      <td>79.5528</td>\n",
              "      <td>44.9929</td>\n",
              "      <td>3.5488</td>\n",
              "      <td>0.1656</td>\n",
              "      <td>0.0900</td>\n",
              "      <td>-39.6213</td>\n",
              "      <td>53.7866</td>\n",
              "      <td>-30.0054</td>\n",
              "      <td>15.8075</td>\n",
              "      <td>311.5680</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19012</th>\n",
              "      <td>31.8373</td>\n",
              "      <td>13.8734</td>\n",
              "      <td>2.8251</td>\n",
              "      <td>0.4169</td>\n",
              "      <td>0.1988</td>\n",
              "      <td>-16.4919</td>\n",
              "      <td>-27.1448</td>\n",
              "      <td>11.1098</td>\n",
              "      <td>11.3663</td>\n",
              "      <td>100.0566</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19013</th>\n",
              "      <td>182.5003</td>\n",
              "      <td>76.5568</td>\n",
              "      <td>3.6872</td>\n",
              "      <td>0.1123</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>192.2675</td>\n",
              "      <td>93.0302</td>\n",
              "      <td>-62.6192</td>\n",
              "      <td>82.1691</td>\n",
              "      <td>283.4731</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19014</th>\n",
              "      <td>43.2980</td>\n",
              "      <td>17.3545</td>\n",
              "      <td>2.8307</td>\n",
              "      <td>0.2877</td>\n",
              "      <td>0.1646</td>\n",
              "      <td>-60.1842</td>\n",
              "      <td>-33.8513</td>\n",
              "      <td>-3.6545</td>\n",
              "      <td>78.4099</td>\n",
              "      <td>224.8299</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19015</th>\n",
              "      <td>21.3846</td>\n",
              "      <td>10.9170</td>\n",
              "      <td>2.6161</td>\n",
              "      <td>0.5857</td>\n",
              "      <td>0.3934</td>\n",
              "      <td>15.2618</td>\n",
              "      <td>11.5245</td>\n",
              "      <td>2.8766</td>\n",
              "      <td>2.4229</td>\n",
              "      <td>106.8258</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19016</th>\n",
              "      <td>28.9452</td>\n",
              "      <td>6.7020</td>\n",
              "      <td>2.2672</td>\n",
              "      <td>0.5351</td>\n",
              "      <td>0.2784</td>\n",
              "      <td>37.0816</td>\n",
              "      <td>13.1853</td>\n",
              "      <td>-2.9632</td>\n",
              "      <td>86.7975</td>\n",
              "      <td>247.4560</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19017</th>\n",
              "      <td>75.4455</td>\n",
              "      <td>47.5305</td>\n",
              "      <td>3.4483</td>\n",
              "      <td>0.1417</td>\n",
              "      <td>0.0549</td>\n",
              "      <td>-9.3561</td>\n",
              "      <td>41.0562</td>\n",
              "      <td>-9.4662</td>\n",
              "      <td>30.2987</td>\n",
              "      <td>256.5166</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19018</th>\n",
              "      <td>120.5135</td>\n",
              "      <td>76.9018</td>\n",
              "      <td>3.9939</td>\n",
              "      <td>0.0944</td>\n",
              "      <td>0.0683</td>\n",
              "      <td>5.8043</td>\n",
              "      <td>-93.5224</td>\n",
              "      <td>-63.8389</td>\n",
              "      <td>84.6874</td>\n",
              "      <td>408.3166</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19019</th>\n",
              "      <td>187.1814</td>\n",
              "      <td>53.0014</td>\n",
              "      <td>3.2093</td>\n",
              "      <td>0.2876</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>-167.3125</td>\n",
              "      <td>-168.4558</td>\n",
              "      <td>31.4755</td>\n",
              "      <td>52.7310</td>\n",
              "      <td>272.3174</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19020 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        fLength    fWidth   fSize   fConc  fConc1     fAsym   fM3Long  \\\n",
              "0       28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   22.0110   \n",
              "1       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
              "2      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
              "3       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
              "4       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
              "5       51.6240   21.1502  2.9085  0.2420  0.1340   50.8761   43.1887   \n",
              "6       48.2468   17.3565  3.0332  0.2529  0.1515    8.5730   38.0957   \n",
              "7       26.7897   13.7595  2.5521  0.4236  0.2174   29.6339   20.4560   \n",
              "8       96.2327   46.5165  4.1540  0.0779  0.0390  110.3550   85.0486   \n",
              "9       46.7619   15.1993  2.5786  0.3377  0.1913   24.7548   43.8771   \n",
              "10      62.7766   29.9104  3.3331  0.2475  0.1261  -33.9065   57.5848   \n",
              "11      18.8562   16.4600  2.4385  0.5282  0.2933   25.1269   -6.5401   \n",
              "12      45.6321   22.7100  3.0441  0.2213  0.1215  -18.3986  -20.6427   \n",
              "13      33.1818   12.4655  2.4955  0.4696  0.2412  -17.0341  -22.0762   \n",
              "14      60.4580   33.1061  3.1944  0.4679  0.2464   14.3000  -33.8765   \n",
              "15      29.4741   22.4581  2.6258  0.3077  0.1740   18.1242   22.7035   \n",
              "16      36.1741   17.6865  2.9460  0.2865  0.1591   -4.7746  -18.9697   \n",
              "17      46.2915   16.0328  2.7756  0.3403  0.1920   49.9706   33.3653   \n",
              "18      46.0588   18.7870  3.2217  0.2431  0.1504   49.2704   34.1066   \n",
              "19      44.7394   15.6364  2.6380  0.3107  0.1715   14.0430   37.2246   \n",
              "20      91.6423   71.8818  3.8484  0.0780  0.0430  -56.7107   72.3016   \n",
              "21      86.0486   21.8287  3.3587  0.2369  0.1662  -58.7854   57.8212   \n",
              "22      90.5299   17.8721  3.0330  0.2122  0.1080  -57.4170   84.6189   \n",
              "23      20.3836    9.0462  2.3365  0.6359  0.3894   22.2700   12.9487   \n",
              "24      87.2384   27.9350  2.8848  0.3155  0.1806  -18.2102   66.6867   \n",
              "25     107.3380   29.1356  3.5265  0.1315  0.0683  -47.1175   89.5136   \n",
              "26      27.2304   19.2817  2.6375  0.3710  0.2039   23.0406   23.3428   \n",
              "27      26.7065   18.9070  2.6781  0.4281  0.2214    9.1616   18.6858   \n",
              "28      23.5647    9.9926  2.2095  0.5679  0.3364   30.0056  -13.8665   \n",
              "29      34.7486   19.2286  2.5629  0.3666  0.1984   30.3637  -16.3092   \n",
              "...         ...       ...     ...     ...     ...       ...       ...   \n",
              "18990   26.0277    7.4010  2.4223  0.6194  0.3791  -27.8670   14.0382   \n",
              "18991   32.1547   12.5410  2.7593  0.4317  0.2167   31.6221   24.5785   \n",
              "18992  169.0402   35.3614  3.2894  0.3349  0.1986 -162.2329   70.4636   \n",
              "18993   18.8377    8.8786  2.5617  0.6039  0.3234    0.4589   15.5433   \n",
              "18994  195.2309   67.0206  3.7669  0.1195  0.0677 -119.1863 -155.8811   \n",
              "18995   67.7139   28.5831  3.2384  0.2050  0.1106 -133.6450   63.1391   \n",
              "18996   29.8353   11.3519  2.4449  0.4890  0.2948    9.9236   -9.0429   \n",
              "18997   18.0124   10.6746  2.5694  0.5768  0.2951  -23.3968   -9.2150   \n",
              "18998  207.2530   75.8327  4.1476  0.0739  0.0371 -242.4960 -180.0290   \n",
              "18999  172.2442   20.1926  2.9009  0.2887  0.1940  124.5990  112.9452   \n",
              "19000   69.3556   31.9822  3.2231  0.3093  0.1744  -52.6569  -42.0622   \n",
              "19001   57.1905   35.5095  2.7177  0.2337  0.1197  -48.5112  -54.2835   \n",
              "19002  110.7140   26.8312  3.2212  0.1856  0.1247 -158.0625   73.2259   \n",
              "19003   21.5189   15.4205  2.7328  0.5587  0.3117   -7.3668    9.2409   \n",
              "19004   23.4293   11.3673  2.7001  0.3842  0.1890  -26.3784  -14.5363   \n",
              "19005   23.8277   11.8989  2.4393  0.4655  0.2891   11.1013   11.5776   \n",
              "19006   32.1454   13.8296  2.4844  0.5182  0.2761  -36.0633  -15.9648   \n",
              "19007  115.2640   14.0075  2.8540  0.7544  0.4136  -88.2076 -117.4860   \n",
              "19008  133.4950   40.1631  3.3050  0.1169  0.0602   84.1711  -81.3323   \n",
              "19009   39.5223   18.6327  2.8341  0.2462  0.1414   24.1819   23.2190   \n",
              "19010   32.4902   10.6723  2.4742  0.4664  0.2735  -27.0097  -21.1687   \n",
              "19011   79.5528   44.9929  3.5488  0.1656  0.0900  -39.6213   53.7866   \n",
              "19012   31.8373   13.8734  2.8251  0.4169  0.1988  -16.4919  -27.1448   \n",
              "19013  182.5003   76.5568  3.6872  0.1123  0.0666  192.2675   93.0302   \n",
              "19014   43.2980   17.3545  2.8307  0.2877  0.1646  -60.1842  -33.8513   \n",
              "19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
              "19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
              "19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
              "19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
              "19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
              "\n",
              "       fM3Trans   fAlpha     fDist class  \n",
              "0       -8.2027  40.0920   81.8828     g  \n",
              "1       -9.9574   6.3609  205.2610     g  \n",
              "2      -45.2160  76.9600  256.7880     g  \n",
              "3       -7.1513  10.4490  116.7370     g  \n",
              "4       21.8393   4.6480  356.4620     g  \n",
              "5        9.8145   3.6130  238.0980     g  \n",
              "6       10.5868   4.7920  219.0870     g  \n",
              "7       -2.9292   0.8120  237.1340     g  \n",
              "8       43.1844   4.8540  248.2260     g  \n",
              "9       -6.6812   7.8750  102.2510     g  \n",
              "10      23.7710   9.9144  323.0940     g  \n",
              "11     -16.9327  11.4610  162.8480     g  \n",
              "12     -14.3164   0.3822  178.2550     g  \n",
              "13      -8.1803  41.9290   41.3816     g  \n",
              "14      28.8315   8.2920  372.5680     g  \n",
              "15      13.1673  48.0364  214.1260     g  \n",
              "16      11.3256   0.2540  191.4550     g  \n",
              "17     -12.7979  38.7070   75.5234     g  \n",
              "18      10.7955   8.6860  180.7830     g  \n",
              "19      12.4183   3.2510  221.8060     g  \n",
              "20      60.0190  16.6220  285.4140     g  \n",
              "21     -18.8093   2.0050  302.5530     g  \n",
              "22      14.9662   2.0390  272.0380     g  \n",
              "23      -2.0403  43.0032   66.1667     g  \n",
              "24     -11.3438   4.4265  342.5040     g  \n",
              "25     -20.0479   3.3120  293.7810     g  \n",
              "26       9.7216  77.5379  104.2830     g  \n",
              "27     -11.6888  26.8810   63.7637     g  \n",
              "28      -8.2600  26.5328  185.1890     g  \n",
              "29      14.3186   1.5210  109.4450     g  \n",
              "...         ...      ...       ...   ...  \n",
              "18990  -12.9981  64.7583  186.2433     h  \n",
              "18991   -9.6861  35.1840  192.5870     h  \n",
              "18992   -9.7764  48.5542  326.2363     h  \n",
              "18993   -8.4175  31.5080  164.8029     h  \n",
              "18994  -40.6133   1.9242  213.1906     h  \n",
              "18995  -16.6379  47.9790  251.9930     h  \n",
              "18996   16.2790  17.1944  230.5486     h  \n",
              "18997    4.7010  52.4630  172.5960     h  \n",
              "18998  -57.8600  74.5740  259.3160     h  \n",
              "18999  -21.4436  28.9553  210.8496     h  \n",
              "19000    6.3984   7.6304  289.2860     h  \n",
              "19001   32.3612  44.7320  102.9950     h  \n",
              "19002   21.2864   9.3725  281.8795     h  \n",
              "19003   17.1609  80.4307  223.9730     h  \n",
              "19004   15.6128  88.3032  269.0718     h  \n",
              "19005    6.8613  35.3166  152.0720     h  \n",
              "19006  -12.2698  47.3704  246.0565     h  \n",
              "19007    8.4777  28.0100  336.9910     h  \n",
              "19008  -31.0503  28.1458  319.3730     h  \n",
              "19009  -12.9245  46.2680  187.0970     h  \n",
              "19010    8.4813  69.1730  120.6680     h  \n",
              "19011  -30.0054  15.8075  311.5680     h  \n",
              "19012   11.1098  11.3663  100.0566     h  \n",
              "19013  -62.6192  82.1691  283.4731     h  \n",
              "19014   -3.6545  78.4099  224.8299     h  \n",
              "19015    2.8766   2.4229  106.8258     h  \n",
              "19016   -2.9632  86.7975  247.4560     h  \n",
              "19017   -9.4662  30.2987  256.5166     h  \n",
              "19018  -63.8389  84.6874  408.3166     h  \n",
              "19019   31.4755  52.7310  272.3174     h  \n",
              "\n",
              "[19020 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "DpDfDBACPB0k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Παρατηρούμε πως όλα τα αντικείμενα της κλάσης g δίνονται στις αρχικές θέσεις του dataset, ενώ όλα τις κλάσης h στις τελικές. Επιλέγουμε να ανακατέψουμε το δείγμα μας.  "
      ]
    },
    {
      "metadata": {
        "id": "6xTvSk5yNJz1",
        "colab_type": "code",
        "outputId": "a2a263c0-98e5-4bac-835e-1aa57b5fd387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "x = shuffle(x).reset_index(drop=True)\n",
        "x.head()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fLength</th>\n",
              "      <th>fWidth</th>\n",
              "      <th>fSize</th>\n",
              "      <th>fConc</th>\n",
              "      <th>fConc1</th>\n",
              "      <th>fAsym</th>\n",
              "      <th>fM3Long</th>\n",
              "      <th>fM3Trans</th>\n",
              "      <th>fAlpha</th>\n",
              "      <th>fDist</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.3306</td>\n",
              "      <td>12.2520</td>\n",
              "      <td>2.6767</td>\n",
              "      <td>0.5511</td>\n",
              "      <td>0.2770</td>\n",
              "      <td>9.4368</td>\n",
              "      <td>14.7230</td>\n",
              "      <td>-6.3487</td>\n",
              "      <td>80.6287</td>\n",
              "      <td>112.5059</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23.3895</td>\n",
              "      <td>17.1735</td>\n",
              "      <td>2.5334</td>\n",
              "      <td>0.4305</td>\n",
              "      <td>0.2592</td>\n",
              "      <td>2.1210</td>\n",
              "      <td>18.7541</td>\n",
              "      <td>-7.6769</td>\n",
              "      <td>12.6605</td>\n",
              "      <td>62.3795</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24.3764</td>\n",
              "      <td>14.5840</td>\n",
              "      <td>2.8487</td>\n",
              "      <td>0.5117</td>\n",
              "      <td>0.3050</td>\n",
              "      <td>9.7548</td>\n",
              "      <td>-11.7233</td>\n",
              "      <td>-7.6942</td>\n",
              "      <td>5.6969</td>\n",
              "      <td>208.7264</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>39.1154</td>\n",
              "      <td>23.9109</td>\n",
              "      <td>3.1608</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.1233</td>\n",
              "      <td>12.9861</td>\n",
              "      <td>30.1010</td>\n",
              "      <td>13.9471</td>\n",
              "      <td>4.2530</td>\n",
              "      <td>118.8900</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.6047</td>\n",
              "      <td>15.4880</td>\n",
              "      <td>2.6785</td>\n",
              "      <td>0.3732</td>\n",
              "      <td>0.2044</td>\n",
              "      <td>7.0597</td>\n",
              "      <td>15.4399</td>\n",
              "      <td>-10.2837</td>\n",
              "      <td>35.3889</td>\n",
              "      <td>112.8150</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fLength   fWidth   fSize   fConc  fConc1    fAsym  fM3Long  fM3Trans  \\\n",
              "0  19.3306  12.2520  2.6767  0.5511  0.2770   9.4368  14.7230   -6.3487   \n",
              "1  23.3895  17.1735  2.5334  0.4305  0.2592   2.1210  18.7541   -7.6769   \n",
              "2  24.3764  14.5840  2.8487  0.5117  0.3050   9.7548 -11.7233   -7.6942   \n",
              "3  39.1154  23.9109  3.1608  0.2238  0.1233  12.9861  30.1010   13.9471   \n",
              "4  25.6047  15.4880  2.6785  0.3732  0.2044   7.0597  15.4399  -10.2837   \n",
              "\n",
              "    fAlpha     fDist class  \n",
              "0  80.6287  112.5059     h  \n",
              "1  12.6605   62.3795     g  \n",
              "2   5.6969  208.7264     h  \n",
              "3   4.2530  118.8900     g  \n",
              "4  35.3889  112.8150     g  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "RaBfzLrQCdsL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Β3. Επικεφαλίδες και αρίθμηση γραμμών\n",
        "\n",
        "Όταν πρωτοδιαβάσαμε το αρχείο παρατηρήσαμε πως δεν υπάρχει επικεφαλίδα οπότε με την επιλογή header=None της εντολής read_table της βιβλιοθήκης pandas εξασφαλίσαμε μια ομαλή απεικόνιση. Όσον αφορά την αρίθμηση, το αρχείο δεν περιείχε απο μόνο του οπότε αφήσαμε το pandas να κάνει τη δουλειά του indexing με τη δική του αρίθμηση. "
      ]
    },
    {
      "metadata": {
        "id": "ExQukl4qCdsM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Β4. Κλάσεις\n",
        "\n",
        "Εύκολα μπορούμε να δούμε απο πάνω πως η κολόνα class βρίσκεται στην 11η θέση και από τα χαρακτηριστικά φαίνεται πως οι ετικέτες των κλάσεων είναι 2 : g,h"
      ]
    },
    {
      "metadata": {
        "id": "TJ03Uj-ECdsN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ### Β5. Μετατροπές στο αρχείο\n",
        "\n",
        "- header = None για να διαβάσουμε το αρχείο χωρίς επικεφαλίδα\n",
        "- sep = \",\" Στην αρχική μορφή όλα τα data ανά στήλη χωρίζονται μεταξύ τους με \",\" , οπότε εξασφαλίζουμε η εντολή read_table να διαβάσει μόνο τα στοιχεία\n",
        "- Δημιουργήσαμε τον πίνακα με τα attributes και τον προσαρμόσαμε στο dataframe\n",
        "- Ανακατέψαμε το δείγμα για να υπάρχουν objects και των δύο κλάσεων σε τυχαίες θέσεις του.\n"
      ]
    },
    {
      "metadata": {
        "id": "-JVzKu4iCdsQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### B6. Απουσιάζουσες τιμές\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Igp-InnECdsS",
        "colab_type": "code",
        "outputId": "fa8a82fb-fb66-4630-84e1-c8ea7fd8651f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x.isnull().values.any()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "7Xwu4KDxqeEE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ελέγχουμε αν υπάρχουν απουσιάζουσες τιμές. **Δεν υπάρχουν.**"
      ]
    },
    {
      "metadata": {
        "id": "9_7xWoPRCdsX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### B7. Έλεγχος εξισορροπημένου dataset"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "g10JzJF1CdsY",
        "colab_type": "code",
        "outputId": "eebaa71e-a8cc-47e5-f1f6-988d42fba0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Έλεγχος μονο της στήλης class\n",
        "y = x.loc[:,'class']\n",
        "\n",
        "# Get dummies για τα classes μας\n",
        "y = pd.get_dummies(y)\n",
        "\n",
        "# Εύρεση ποσοστών δειγμάτων επί του συνόλου\n",
        "avg = (y.T.sum(axis=1))/x.shape[0]\n",
        "print(\"g samples are\", avg[0]*100,\"% of the dataset\")\n",
        "print(\"h samples are\", avg[1]*100,\"% of the dataset\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "g samples are 64.83701366982125 % of the dataset\n",
            "h samples are 35.16298633017876 % of the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F71ZzCQaCdsd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To binary αυτό dataset ειναι **ΜΗ ΙΣΟΡΡΟΠΗΜΕΝΟ** γιατί έχουμε την κλάση g στο 65% σχεδόν των δειγμάτων ενώ την h στο 35% περίπου."
      ]
    },
    {
      "metadata": {
        "id": "-2kWB91aCdsf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### B8. Διαχωρισμός σε train και test set (30%)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "28JBTaF5Cdsg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = np.array(x.drop(['class'],1))\n",
        "labels = np.array(x['class'])\n",
        "\n",
        "train, test, train_labels, test_labels = train_test_split(features,labels,test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W1bDMphbCdsl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "# Γ. Baseline classification\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "xPEmEuEaCdsn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ***Γ1. Train - Test ***"
      ]
    },
    {
      "metadata": {
        "id": "lUKy71jXCdso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Δημιουργούμε μια συνάρτηση, την ***mets*** που θα τυπώνει και θα επιστρέφει τις f1 micro και macro για κάθε ταξινομητή, καθώς και μία άλλη συνάρτηση, την ***conmat*** που θα δημιουργεί και θα τυπώνει το confusion matrix του κάθε ταξινομητή στη μορφή που θέλουμε, καθώς και το classification report. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "cAQJZmUKCdso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def mets(lbls,prds,name):    \n",
        "    f1_micro = f1_score(lbls, prds,average='micro')\n",
        "    f1_macro = f1_score(lbls, prds,average='macro')\n",
        "    print(\"**\" + name + \" AVGS**\")\n",
        "    print(\"f1 micro avg = \" ,f1_micro)\n",
        "    print(\"f1 macro avg = \" ,f1_macro,\"\\n\")\n",
        "    return [f1_micro,f1_macro]\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mkViliCICdst",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def conmat(lbls,prds,lb_names):\n",
        "    # Compute confusion matrix\n",
        "    cnf_matrix = confusion_matrix(lbls, prds)\n",
        "    df = pd.DataFrame(cnf_matrix)\n",
        "    df.columns = lb_names\n",
        "    df['Class'] = lb_names\n",
        "    df.set_index(\"Class\",inplace=True)     \n",
        "    print(classification_report(lbls, prds, target_names=lb_names))\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sJMMA7vTCdsx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## a) Dummy \n"
      ]
    },
    {
      "metadata": {
        "id": "eY4N4OMxycDu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Για τον Dummy ταξινομητή, επιλέξαμε να μην παρουσιάσουμε τα αποτελέσματα μόνο για τη deafult στρατηγική (stratified), αλλά και για τις υπόλοιπες στρατηγικές του, μιας και δε θα ασχοληθούμε άλλο μαζί του στο μέρος Δ."
      ]
    },
    {
      "metadata": {
        "id": "4GXbcKUzCdsy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dummy Metrics"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "n1-Xjo9GCdsz",
        "colab_type": "code",
        "outputId": "17a343b7-8b43-43db-901f-fb616dc2837a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
        "dc_constant_g = DummyClassifier(strategy=\"constant\", constant='g')\n",
        "dc_constant_h = DummyClassifier(strategy=\"constant\", constant='h')\n",
        "dc_stratified = DummyClassifier(strategy=\"stratified\")\n",
        "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dc_prior = DummyClassifier(strategy=\"prior\")\n",
        "\n",
        "#με τη μέθοδο fit \"εκπαιδεύουμε\" τον ταξινομητή στο σύνολο εκπαίδευσης (τα χαρακτηριστικά και τις ετικέτες τους)\n",
        "\n",
        "dc_uniform.fit(train, train_labels)\n",
        "dc_constant_g.fit(train, train_labels)\n",
        "dc_constant_h.fit(train, train_labels)\n",
        "dc_stratified.fit(train, train_labels)\n",
        "dc_most_frequent.fit(train, train_labels)\n",
        "dc_prior.fit(train, train_labels)\n",
        "\n",
        "#με τη μέθοδο predict παράγουμε προβλέψεις για τα δεδομένα ελέγχου (είσοδος τα χαρακτηριστικά μόνο)\n",
        "preds_uniform = dc_uniform.predict(test)\n",
        "preds_constant_g = dc_constant_g.predict(test)\n",
        "preds_constant_h = dc_constant_h.predict(test)\n",
        "preds_stratified = dc_stratified.predict(test)\n",
        "preds_most_frequent = dc_most_frequent.predict(test)\n",
        "preds_prior = dc_prior.predict(test)\n",
        "\n",
        "dummy_metrics_uniform = mets(test_labels,preds_uniform,\"DUMMY UNIFORM\")\n",
        "dummy_metrics_g = mets(test_labels,preds_constant_g,\"DUMMY G\")\n",
        "dummy_metrics_h = mets(test_labels,preds_constant_h,\"DUMMY H\")\n",
        "dummy_metrics_stratified = mets(test_labels,preds_stratified,\"(DEFAULT) STRATIFIED\")\n",
        "dummy_metrics_most_frequent = mets(test_labels,preds_most_frequent,\"MOST FREQUENT\")\n",
        "dummy_metrics_prior = mets(test_labels,preds_prior,\"PRIOR\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**DUMMY UNIFORM AVGS**\n",
            "f1 micro avg =  0.5066596565019278\n",
            "f1 macro avg =  0.4946116978724776 \n",
            "\n",
            "**DUMMY G AVGS**\n",
            "f1 micro avg =  0.6437083771468629\n",
            "f1 macro avg =  0.39161957564772365 \n",
            "\n",
            "**DUMMY H AVGS**\n",
            "f1 micro avg =  0.35629162285313704\n",
            "f1 macro avg =  0.2626954386871689 \n",
            "\n",
            "**(DEFAULT) STRATIFIED AVGS**\n",
            "f1 micro avg =  0.5418857343147564\n",
            "f1 macro avg =  0.49851701685170224 \n",
            "\n",
            "**MOST FREQUENT AVGS**\n",
            "f1 micro avg =  0.6437083771468629\n",
            "f1 macro avg =  0.39161957564772365 \n",
            "\n",
            "**PRIOR AVGS**\n",
            "f1 micro avg =  0.6437083771468629\n",
            "f1 macro avg =  0.39161957564772365 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h377Ocy5Cds2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dummy Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Buehc5YjCds4",
        "colab_type": "code",
        "outputId": "e8f453f9-c81b-4341-f7ff-7baee7e932cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "label_names = np.array(['g','h'])\n",
        "\n",
        "print('\\n Uniform Matices \\n')\n",
        "uni_conmat = conmat(test_labels,preds_uniform,label_names)\n",
        "uni_conmat"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Uniform Matices \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.65      0.51      0.57      3673\n",
            "           h       0.36      0.49      0.42      2033\n",
            "\n",
            "   micro avg       0.51      0.51      0.51      5706\n",
            "   macro avg       0.50      0.50      0.49      5706\n",
            "weighted avg       0.54      0.51      0.52      5706\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>1886</td>\n",
              "      <td>1787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>1028</td>\n",
              "      <td>1005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g     h\n",
              "Class            \n",
              "g      1886  1787\n",
              "h      1028  1005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "id": "wejqZRXjCdtA",
        "colab_type": "code",
        "outputId": "b598c2ff-c646-4580-838d-61aaac99f6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "print('\\n Constant g Matices \\n')\n",
        "constant_g_conmat = conmat(test_labels,preds_constant_g,label_names)\n",
        "constant_g_conmat"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Constant g Matices \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.64      1.00      0.78      3673\n",
            "           h       0.00      0.00      0.00      2033\n",
            "\n",
            "   micro avg       0.64      0.64      0.64      5706\n",
            "   macro avg       0.32      0.50      0.39      5706\n",
            "weighted avg       0.41      0.64      0.50      5706\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3673</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>2033</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g  h\n",
              "Class         \n",
              "g      3673  0\n",
              "h      2033  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Erm1QydhCdtE",
        "colab_type": "code",
        "outputId": "46fa7350-0bb0-493c-d1c2-ffd291a05d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "print('\\n Constant h Matices \\n')\n",
        "constant_h_conmat = conmat(test_labels,preds_constant_g,label_names)\n",
        "constant_h_conmat"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Constant h Matices \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.64      1.00      0.78      3673\n",
            "           h       0.00      0.00      0.00      2033\n",
            "\n",
            "   micro avg       0.64      0.64      0.64      5706\n",
            "   macro avg       0.32      0.50      0.39      5706\n",
            "weighted avg       0.41      0.64      0.50      5706\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3673</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>2033</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g  h\n",
              "Class         \n",
              "g      3673  0\n",
              "h      2033  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "JTzNvwgYmRKM",
        "colab_type": "code",
        "outputId": "991f9dc9-35f9-4c9f-910b-a6a9eaece316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "print('\\n Stratified Matices \\n')\n",
        "stratified_conmat = conmat(test_labels,preds_stratified,label_names)\n",
        "stratified_conmat"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Stratified Matices \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.64      0.65      0.65      3673\n",
            "           h       0.35      0.35      0.35      2033\n",
            "\n",
            "   micro avg       0.54      0.54      0.54      5706\n",
            "   macro avg       0.50      0.50      0.50      5706\n",
            "weighted avg       0.54      0.54      0.54      5706\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>2385</td>\n",
              "      <td>1288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>1326</td>\n",
              "      <td>707</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g     h\n",
              "Class            \n",
              "g      2385  1288\n",
              "h      1326   707"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "jtOciAo5mbi1",
        "colab_type": "code",
        "outputId": "6e77a39d-2ada-4323-d419-8e78ef52614d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "print('\\n Most Frequent Matices \\n')\n",
        "most_frequent_conmat = conmat(test_labels,preds_most_frequent,label_names)\n",
        "most_frequent_conmat"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Most Frequent Matices \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.64      1.00      0.78      3673\n",
            "           h       0.00      0.00      0.00      2033\n",
            "\n",
            "   micro avg       0.64      0.64      0.64      5706\n",
            "   macro avg       0.32      0.50      0.39      5706\n",
            "weighted avg       0.41      0.64      0.50      5706\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3673</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>2033</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g  h\n",
              "Class         \n",
              "g      3673  0\n",
              "h      2033  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "epRpygTMmnkg",
        "colab_type": "code",
        "outputId": "6a5f0dbf-09c1-4c74-c1f8-7bc076245ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "print('\\n Prior Matices \\n')\n",
        "prior_conmat = conmat(test_labels,preds_prior,label_names)\n",
        "prior_conmat"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Prior Matices \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.64      1.00      0.78      3673\n",
            "           h       0.00      0.00      0.00      2033\n",
            "\n",
            "   micro avg       0.64      0.64      0.64      5706\n",
            "   macro avg       0.32      0.50      0.39      5706\n",
            "weighted avg       0.41      0.64      0.50      5706\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3673</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>2033</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g  h\n",
              "Class         \n",
              "g      3673  0\n",
              "h      2033  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "Wxo2MPezCdtI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## b) Gaussian Naive Bayes"
      ]
    },
    {
      "metadata": {
        "id": "bi2itf6WCdtJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GNB Metrics"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "id": "E7NZQyvYCdtL",
        "colab_type": "code",
        "outputId": "218c9374-6ff5-4ebc-c91e-b298ba475225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "model = gnb.fit(train, train_labels)\n",
        "preds_gnb = gnb.predict(test)\n",
        "\n",
        "gnb_metrics = mets(test_labels,preds_gnb,\"GNB\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**GNB AVGS**\n",
            "f1 micro avg =  0.7253767963547143\n",
            "f1 macro avg =  0.654871860886522 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d_NEcDLJCdtO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GNB Confusion Matrix\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Br3EG9HiCdtO",
        "colab_type": "code",
        "outputId": "84eb7141-9ff5-4bb8-85cc-c3fd06ccd59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Gausian Naive Bayes Confusion Matrices \\n\")\n",
        "gnb_conmat = conmat(test_labels,preds_gnb,label_names)\n",
        "gnb_conmat"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gausian Naive Bayes Confusion Matrices \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.73      0.91      0.81      3673\n",
            "           h       0.71      0.38      0.50      2033\n",
            "\n",
            "   micro avg       0.73      0.73      0.73      5706\n",
            "   macro avg       0.72      0.65      0.65      5706\n",
            "weighted avg       0.72      0.73      0.70      5706\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3359</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>1253</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g    h\n",
              "Class           \n",
              "g      3359  314\n",
              "h      1253  780"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "p1AQpDk4CdtS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## c) kNN"
      ]
    },
    {
      "metadata": {
        "id": "SivXr3y8CdtT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### kNN Metrics"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "id": "OhvpMJEGCdtV",
        "colab_type": "code",
        "outputId": "fd168248-46ab-4ac4-d1aa-1d1c94d31f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(train,train_labels)\n",
        "preds_knn = knn.predict(test)\n",
        "\n",
        "knn_metrics = mets(test_labels,preds_knn,\"kNN\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**kNN AVGS**\n",
            "f1 micro avg =  0.8003855590606379\n",
            "f1 macro avg =  0.766232286364041 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wbO39PFVCdtZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### kNN Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "5Yh8ejAhCdta",
        "colab_type": "code",
        "outputId": "712f6e54-6458-455d-9caa-ee9927fe7847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"kNN Confusion Matrices \\n\")\n",
        "knn_conmat = conmat(test_labels,preds_knn,label_names)\n",
        "knn_conmat"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kNN Confusion Matrices \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.80      0.92      0.86      3673\n",
            "           h       0.80      0.59      0.68      2033\n",
            "\n",
            "   micro avg       0.80      0.80      0.80      5706\n",
            "   macro avg       0.80      0.75      0.77      5706\n",
            "weighted avg       0.80      0.80      0.79      5706\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3374</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>840</td>\n",
              "      <td>1193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g     h\n",
              "Class            \n",
              "g      3374   299\n",
              "h       840  1193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "91euZmhZCdth",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## d) MLP"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XkYXlVHmotda"
      },
      "cell_type": "markdown",
      "source": [
        "### MLP Metrics"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "outputId": "2c69089b-bcde-4380-818b-ec7f8c77da27",
        "id": "Np7byTkGotdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(1,))\n",
        "mlp.fit(train, train_labels)\n",
        "preds_mlp = mlp.predict(test)\n",
        "\n",
        "mlp_metrics = mets(test_labels,preds_mlp,\"MLP\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**MLP AVGS**\n",
            "f1 micro avg =  0.64931650893796\n",
            "f1 macro avg =  0.4106769930745795 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "M0OqxLH7otdh"
      },
      "cell_type": "markdown",
      "source": [
        "### MLP Confusion Matrix\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "outputId": "dc0b3866-6e2f-48f0-8b32-66adf6cd5128",
        "id": "y3Yd_-Evotdi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Multi-layer Perceptron Confusion Matrices \\n\")\n",
        "mlp_conmat = conmat(test_labels,preds_mlp,label_names)\n",
        "mlp_conmat"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multi-layer Perceptron Confusion Matrices \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.65      1.00      0.79      3673\n",
            "           h       0.88      0.02      0.04      2033\n",
            "\n",
            "   micro avg       0.65      0.65      0.65      5706\n",
            "   macro avg       0.76      0.51      0.41      5706\n",
            "weighted avg       0.73      0.65      0.52      5706\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3668</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>1996</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g   h\n",
              "Class          \n",
              "g      3668   5\n",
              "h      1996  37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "Tzoada6VCdtw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ***Γ2. Bar Plot***"
      ]
    },
    {
      "metadata": {
        "id": "xN-sIK04nZM4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Τυπώνουμε τα f1-metrics των ταξινομητών, πλην των most_frequent και prior, τα οποία όπως αναμέναμε έχουν τα ίδια metrics με το constant_g, αφού το dataset είναι μη ισορροπημένο με τα δείγματα κλάσης g στο 65% περίπου. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "tNa2id9oCdty",
        "colab_type": "code",
        "outputId": "cc1e5a1d-7818-4409-a027-01b5b593096d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "x_axis = ['F1 Micro','F1 Macro']\n",
        "\n",
        "ind = np.arange(len(x_axis))\n",
        "\n",
        "plt.xticks(ind,x_axis)\n",
        "\n",
        "plt.title(\"Classifier Metrics\")\n",
        "plt.bar(ind-0.3,dummy_metrics_uniform,width=0.1,label=\"Uniform\") \n",
        "plt.bar(ind-0.2,dummy_metrics_g,width=0.1,label=\"g Const\") \n",
        "plt.bar(ind-0.1,dummy_metrics_h,width=0.1,label=\"h Const\") \n",
        "plt.bar(ind,dummy_metrics_stratified,width=0.1,label=\"Stratified\") \n",
        "plt.bar(ind+0.1,gnb_metrics,width=0.1,label=\"GNB\")\n",
        "plt.bar(ind+0.2,knn_metrics,width=0.1,label=\"kNN\") \n",
        "plt.bar(ind+0.3,mlp_metrics,width=0.1,label=\"MLP\")\n",
        "plt.legend()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f52bdecb160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABiEEAYAwCCEMAAABiGEAQAwyP8DkMNsFs8bmNIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f52bdecb048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3pFHCpHKGODS"
      },
      "cell_type": "markdown",
      "source": [
        "## Γ3. Σχολιασμός Αποτελεσμάτων"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "aRJyqIdY4yhu"
      },
      "cell_type": "markdown",
      "source": [
        "Παρατηρούμε πως για τους ταξινομητές με default τιμές, και **MLP με ένα μόνο επίπεδο κρυφών νευρώνων**, καλύτερες μετρικές παρουσιάζει ο kNN με τον Gaussian Naive Βayes να ακολουθεί. \n",
        "(Σημειωτέον πως για default MLP, το οποίο έχει προφανώς περισσότερα επίπεδα κρυφών νευρώνων το MLP παρέχει τις καλύτερες μετρικές που ξεπερνάνε το 80%.) Η χειρότερη απόδοση προκύπτει όπως αναμέναμε από τον h-constant dummy, αφού το dataset είναι μη εξισορροπημένο. \n",
        "\n",
        "Παρατηρούμε στους Dummies από τους comfusion matrices πως σε πολλούς -όπως αναμέναμε- όλα τα δείγματα προβλέπεται πως ανήκουν σε μία τάξη και πως με stratified dummy οι τιμές precision και recall είναι ίσες για τις δύο κλάσεις ξεχωριστά. \n",
        "\n",
        "Παρατηρούμε ακόμη μεγάλη διαφορά στα δύο recall του kΝΝ και αυτό λόγω των False Negative προβλέψεων στις οποίες προβαίνει ο μη βελτιστοποιημένος ταξινομητής.\n",
        "\n",
        "Στον GNB έχουμε ιδιαίτερα μικρό f1-score για την κλάση h, πάλι λόγω του αριθμού των αντικειμένων της, ενώ για τον MLP έχουμε ελάχιστες προβλέψεις αντικειμένου της κλασης h! Είναι και αυτό εξαιτίας της ιδιαιτερότητας στην εξισορρόπηση του dataset μας. Υπήρξαν για διαφορετικές εκτελέσεις και περιπτώσεις που κανένα στοιχείο δεν ταξινομήθηκε ως h!\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jbt7nbtsCdt3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "# Δ. Βελτιστοποίηση ταξινομητών\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "bpQYSd7rsk8E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Δ1. Grid Search Cross Validation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LwOYHC5yCdt4",
        "colab_type": "code",
        "outputId": "c9877a1a-920c-45db-da10-b0237f3769b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade imbalanced-learn"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.20.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.15.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zW5-9F_nGIOA"
      },
      "cell_type": "markdown",
      "source": [
        "Εισάγουμε τις γνωστές μας κλάσεις για προεπεξεργασία δεδομένων.\n",
        "\n",
        "Σημειωτέον επίσης πως χαριν απλότητας  παρουσίασης και επιτάχυνσης της εκτέλεσης δεν συμπεριλαμβάνονται όλοι οι δυνατοί συνδυασμοί pipeline, αλλά 7 ενδεικτικοί για κάθε ταξινομιτή και μετρική, ικανοί για να σημειωθούν οι διαφορές στα αποτελέσματα με την προσθήκη ή την αφαίρεση κάποιου σταδίου σωλήνωσης, αλλά και να μας οδηγήσουν (έπειτα και από πειραματική εξακρίβωση μέσω διαφορετικών εκτελέσεων) στη βέλτιστη κατά το δυνατόν ακρίβεια .\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "sycsym9ACduB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# φέρνουμε τις γνωστές μας κλάσεις για preprocessing\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# αρχικοποιούμε τους μετασχηματιστές χωρίς παραμέτρους\n",
        "selector = VarianceThreshold()\n",
        "scaler = StandardScaler()\n",
        "ros = RandomOverSampler()\n",
        "pca = PCA()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-U40OVRfGLGN"
      },
      "cell_type": "markdown",
      "source": [
        "Θα δημιουργήοσυμε επίσης μια συνάρτηση ***cv_best*** που αφου βρει αρχικά το βέλτιστο pipeline και τις βέλτιστες υπερπαραμέτρους για το cross validation, τις παραμέτρους που δίνουν δηλαδή καλύτερη ακρίβεια για τα δεδομένα του train set, θα κάνει predict στο test set μας, θα τυπώνει την αντίστοιχη μετρική και θα επιστρέφει τον estimator με τις βέλτιστες παραμέτρους."
      ]
    },
    {
      "metadata": {
        "id": "CMEm--d3bOeF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def cv_best(est,tr,trl,name):\n",
        "    start_time = time.time()\n",
        "    est.fit(tr,trl)\n",
        "    preds = est.predict(test)\n",
        "    print(\"Συνολικός χρόνος GridSearchCV: %s seconds\" % (time.time() - start_time))\n",
        "    cm = conmat(test_labels,preds,label_names)\n",
        "    res = f1_score(test_labels, preds, average=name)\n",
        "    print ('Optimum f1-',name,' is', res)\n",
        "    return [est.best_estimator_,res,cm] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P4NIs05rCdvF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## GNB\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "EWCo37ABo18o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Progressive Grid Search"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EumWs9O80wL1"
      },
      "cell_type": "markdown",
      "source": [
        "Αρχικά, αναζητώντας τη variance για οποιοδήποτε από τους ταξινομητές που χρησιμοποιήσαμε στο μέρος Γ με την εντολή: train_variance = train.var(axis=0) προκύπτουν για διάφορα train sets που δοκιμάσαμε τιμές λίγο μεγαλύτερες από 5000. Ξεκινήσαμε λοιπόν αρικά με διάστημα αναζήτησης vthreshold = [0, 1000, 3000, 5000]. Παρατηρήσαμε πως κάθε φορά επιλεγόταν η τιμή 0, γεγονός που επαναλαμβανόταν για όλες τις μετατοπίσεις του διαστήματος που επιχειρούσαμε προς το 0, μέχρι τη δοκιμή [0,0.01,0.02,0.03,0.04] για την οποία επιλέχθηκε το 0.02.\n",
        "\n",
        "Φτάσαμε λοιπόν μετά από δοκιμές στα εξής διαστήματα αναζήτησης:\n",
        "\n",
        "- vthreshold = [0,0.01,0.02,0.03]\n",
        "- n_components= [6,7,8]\n",
        "- var_smoothing=[1e-08,1e-07,1e-06]\n",
        "\n",
        "Για GridSearchCV σε ολόκληρο το train_set για f1-micro επιλέγεται το εξής pipeline:\n",
        "     - (steps=[('selector', VarianceThreshold(threshold=0.02)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sampler', None), ('pca', PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
        "    svd_solver='auto', tol=0.0, whiten=False)), ('gnb', GaussianNB(priors=None, var_smoothing=1e-08))])\n",
        "  \n",
        " Συνολικός χρόνος GridSearchCV: 95.44038772583008 seconds\n",
        " \n",
        " Μετατοπίζουμε λοιπόν τα διαστήματα ωστε να φέρουμε στο κέντρο τους τις τιμές που επιλέχθηκαν, εκτός του pca_n_components που επιλέγεται σε όλες μας τις δοκιμές ίσο με 8 και δε μπορούμε να βάλουμε μεγαλύτερη τιμή, γιατί όταν ο selector αφαιρεί χαρακτηριστικά προκύπτει error κατά την εκτέλεση. Για αυτό το λόγο επιχειρήσαμε να δώσουμε τις τιμές [8,9,10] στο pipe που έχει pca και όχι selector, αλλά και πάλι βέλτιστο επιλέχθηκε αυτό που αποτελείται και από τα δύο στάδια.Επίσης, το var_smoothing για όλες τι δοκιμές μας να μετατοπίσουμε το εύρος αναζήτησης της τιμής του επιλέχθηκε ίσο με 1e-08. \n",
        " \n",
        " Από αυτά επιλέγουμε τα διαστήματα αναζήτησης υπερπαραμετρων που παρουσιάζονται στον κώδικα παρακάτω:\n"
      ]
    },
    {
      "metadata": {
        "id": "WFZmCmD3Oq49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vthreshold = [0.01,0.02,0.03]\n",
        "n_components= [8]\n",
        "var_smoothing=[1e-08,1e-07]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9aUxpXTkCdvF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Ορίζουμε τον gnb ταξινομητή\n",
        "clf = GaussianNB()\n",
        "\n",
        "gnb_pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', ros), ('pca',pca),('gnb', clf)], memory = 'tmp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Ezg_RZVa01i7"
      },
      "cell_type": "markdown",
      "source": [
        "Για να εισάγουμε και τα διάφορα pipelines ως παραμέτρους προς cross validation, δημιουργήσαμε τη παρακάτω λίστα από dictionarys. Δίνουμε μεν ως pipeline το pipe που αποτελείται από όλα τα στάδια προεπεξεργασίας που έχουμε και τον ταξινομητή, όταν ωστόσο δίνεται η τιμή *None* σε κάποιο στάδιο εξ αυτών, αυτό αφαιρείται. Έτσι δημιουργήσαμε το παρακάτω grid με 7 pipelines.\n",
        "\n",
        "Για τη δημιουργία του συμβουλευτήκαμε το διαδίκτυο, λαμβάνοντας ιδιαίτερη βοήθεια από τον εξής σύνδεσμο:\n",
        "\n",
        "https://stackoverflow.com/questions/50265993/alternate-different-models-in-pipeline-for-gridsearchcv"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gBMAvnTZch0R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gnb_params_grid = [dict(selector = [None], scaler = [None] , sampler = [None],pca = [None],gnb__var_smoothing = var_smoothing),\n",
        "                   dict(selector = [None], scaler = [None] ,pca = [None],gnb__var_smoothing = var_smoothing),\n",
        "                   dict(selector = [None], scaler = [None] ,pca__n_components = n_components,gnb__var_smoothing = var_smoothing),\n",
        "                   dict(selector = [None], pca__n_components = n_components,gnb__var_smoothing = var_smoothing),    \n",
        "                   dict(selector__threshold=vthreshold, scaler = [None] , sampler = [None],pca = [None],gnb__var_smoothing = var_smoothing),\n",
        "                   dict(selector__threshold=vthreshold, sampler = [None],pca__n_components = n_components,gnb__var_smoothing = var_smoothing),\n",
        "                   dict(selector__threshold=vthreshold,pca__n_components = n_components,gnb__var_smoothing = var_smoothing)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fNr70qnjgwTm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "gnb_micro_estimator = GridSearchCV(gnb_pipe,param_grid=gnb_params_grid,cv=5, scoring='f1_micro', n_jobs=-1)\n",
        "gnb_macro_estimator = GridSearchCV(gnb_pipe,param_grid=gnb_params_grid,cv=5, scoring='f1_macro', n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T-gZuhoeCdvI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### a) f1- micro"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "outputId": "0c37a556-6952-40c7-e4be-6a08a3ad1e4b",
        "id": "z4egoLHmdkEU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "gnb_micro = cv_best(gnb_micro_estimator,train,train_labels,'micro')\n",
        "print('\\nConfusion Matrix\\n')\n",
        "gnb_micro[2]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος GridSearchCV: 29.160797357559204 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.76      0.91      0.83      3673\n",
            "           h       0.75      0.48      0.58      2033\n",
            "\n",
            "   micro avg       0.76      0.76      0.76      5706\n",
            "   macro avg       0.76      0.69      0.71      5706\n",
            "weighted avg       0.76      0.76      0.74      5706\n",
            "\n",
            "Optimum f1- micro  is 0.757974062390466\n",
            "\n",
            "Confusion Matrix\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3359</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>1067</td>\n",
              "      <td>966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g    h\n",
              "Class           \n",
              "g      3359  314\n",
              "h      1067  966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4da6379d-8d7a-4d4d-95c6-a6ce27dbd4ba",
        "id": "b1I1DRMIdkEZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Optimum GNB f1-micro is\",gnb_micro[0])\n",
        "\n",
        "start_time = time.time()\n",
        "gnb_micro[0].fit(train,train_labels)\n",
        "preds = gnb_micro[0].predict(test)\n",
        "gnb_micro_time = time.time() - start_time\n",
        "print(\"\\n Συνολικός χρόνος fit και predict: %s seconds \\n\" % gnb_micro_time)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimum GNB f1-micro is Pipeline(memory='tmp',\n",
            "     steps=[('selector', VarianceThreshold(threshold=0.02)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sampler', None), ('pca', PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
            "  svd_solver='auto', tol=0.0, whiten=False)), ('gnb', GaussianNB(priors=None, var_smoothing=1e-08))])\n",
            "\n",
            " Συνολικός χρόνος fit και predict: 0.22082114219665527 seconds \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "En8WfkfQdwOi"
      },
      "cell_type": "markdown",
      "source": [
        "### b) f1- macro"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "outputId": "6b786e72-d8c4-4025-ad8d-034007dff9fc",
        "id": "V4fLL3ApdwOk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "gnb_macro = cv_best(gnb_macro_estimator,train,train_labels,'macro')\n",
        "print('\\nConfusion Matrix\\n')\n",
        "gnb_macro[2]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος GridSearchCV: 20.095083236694336 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.77      0.86      0.82      3673\n",
            "           h       0.69      0.54      0.61      2033\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      5706\n",
            "   macro avg       0.73      0.70      0.71      5706\n",
            "weighted avg       0.74      0.75      0.74      5706\n",
            "\n",
            "Optimum f1- macro  is 0.7130202603593694\n",
            "\n",
            "Confusion Matrix\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3177</td>\n",
              "      <td>496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>926</td>\n",
              "      <td>1107</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g     h\n",
              "Class            \n",
              "g      3177   496\n",
              "h       926  1107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c780e20e-6f0f-4ebd-8dc5-47e664cae987",
        "id": "OOgz30EddwOq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Optimum GNB f1-macro is\",gnb_macro[0])\n",
        "\n",
        "start_time = time.time()\n",
        "gnb_macro[0].fit(train,train_labels)\n",
        "preds = gnb_macro[0].predict(test)\n",
        "gnb_macro_time = time.time() - start_time\n",
        "print(\"\\n Συνολικός χρόνος fit και predict: %s seconds\" % gnb_macro_time)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimum GNB f1-macro is Pipeline(memory='tmp',\n",
            "     steps=[('selector', VarianceThreshold(threshold=0.01)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sampler', RandomOverSampler(random_state=None, ratio=None, return_indices=False,\n",
            "         sampling_strategy='auto')), ('pca', PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
            "  svd_solver='auto', tol=0.0, whiten=False)), ('gnb', GaussianNB(priors=None, var_smoothing=1e-08))])\n",
            "\n",
            " Συνολικός χρόνος fit και predict: 0.3076786994934082 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U0XavzKKCduH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## kNN\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "Oq8ks7HAZ2bM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Θα εκτελέσουμε αρχικά GridSearchCV στο 1/4 του trainset μας διότι είναι πολύ μεγάλο"
      ]
    },
    {
      "metadata": {
        "id": "aG9isiY1ZIW0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "quarter = train.shape[0] // 4\n",
        "qtrain = train[1:quarter]\n",
        "qtrain_labels = train_labels[1:quarter]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7f01v7ZG6ki",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Progressive Grid Search"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0mOMyy9T09dU"
      },
      "cell_type": "markdown",
      "source": [
        "Αντίστοιχα με πριν για το vthreshold δίνουμε στην GridSearchCV τα παρακάτω ορίσματα:\n",
        "- vthreshold = [0.01,0.02,0.03]\n",
        "- k = [11, 13, 15, 17]\n",
        "- weights = ['uniform','distance']\n",
        "- metric = ['euclidean','manhattan','chebyshev','minkowski']\n",
        "και τρεχουμε για το 1/4 του train set μας καλώντας τη συνάρτηση cv_best δίνοντας για όρισμα τα qtrain και qtrain_labels. \n",
        "\n",
        "Για όλες τις εκτελέσεις μας το GridSearchCV επέλεξε *weight = distance* και *metric = manhattan* για βέλτιστη απόδοση,  για να προχωρήσουμε λοιπόν για τη διαδικασία σε oλκληρο το train set επιλέγουμε αυτές τις υπερπαραμέτρους ως βέλτιστες και συνεχίζουμε την αναζήτηση για τις αριθμητικές μας μεταβλητές. Για το k του classifier επιλέχθηκε η ακραία τιμή 17 οπότε μετατοπίζουμε το διάστημα προς την τιμή αυτή. Μετά απο μετατοπίσεις του διαστήματος k προς τα πάνω, είδαμε πως επιλέγεγεται η τιμή 17 για f1-micro και 21 για f1-macro, γι αυτό τρέξαμε και το τελικό cv στο παρακάτω διάστημα. Το var threshold βρίσκεται ήδη στο μέσο του διαστήματος αναζήτησης.\n",
        "\n",
        "           (steps =['selector', VarianceThreshold(threshold=0.02)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)),  ('sampler', None), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
        "    svd_solver='auto', tol=0.0, whiten=False)), ('kNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
        "           metric_params=None, n_jobs=-1, n_neighbors=17, p=2,\n",
        "           weights='distance'))])\n",
        " \n",
        " Συνολικός χρόνος GridSearchCV: 273.32881831631907 seconds\n",
        "           \n",
        "  Μεταβάλουμε λοιπόν τις μεταβλητές όπως περιγράφηκε και δοκιμάζουμε, αυτή τη φορά για όλο το train set.\n",
        "           \n",
        "\n",
        "  \n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "gDQJG9O_CduT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "clf = neighbors.KNeighborsClassifier(n_jobs=-1)\n",
        "\n",
        "vthreshold = [0.01,0.02,0.03]\n",
        "k = [17, 19,21] \n",
        "weights = ['distance']\n",
        "metric = ['manhattan']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pjQapwjLJKMl",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn_pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', ros), ('pca',pca),('kNN', clf),], memory = 'tmp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzS05ad9VL7T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn_params_grid = [dict(selector = [None], scaler = [None] , sampler = [None], pca = [None],kNN__n_neighbors=k,kNN__weights=weights, kNN__metric = metric),\n",
        "                   dict(selector = [None], scaler = [None] ,pca = [None], kNN__n_neighbors=k,kNN__weights=weights, kNN__metric = metric),\n",
        "                   dict(selector = [None], scaler = [None] ,pca__n_components = n_components, kNN__n_neighbors=k,kNN__weights=weights, kNN__metric = metric),\n",
        "                   dict(selector = [None], pca__n_components = n_components,  kNN__n_neighbors=k,kNN__weights=weights, kNN__metric = metric),\n",
        "                   dict(selector__threshold=vthreshold, scaler = [None] ,sampler = [None],pca=[None], kNN__n_neighbors=k,kNN__weights=weights, kNN__metric = metric),\n",
        "                   dict(selector__threshold=vthreshold, sampler = [None],pca__n_components = n_components, kNN__n_neighbors=k,kNN__weights=weights, kNN__metric = metric),\n",
        "                   dict(selector__threshold=vthreshold,pca__n_components = n_components, kNN__n_neighbors=k,kNN__weights=weights, kNN__metric = metric)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LConevASWHbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn_micro_estimator = GridSearchCV(knn_pipe,param_grid=knn_params_grid,cv=5, scoring='f1_micro', n_jobs=-1)\n",
        "knn_macro_estimator = GridSearchCV(knn_pipe,param_grid=knn_params_grid,cv=5, scoring='f1_macro', n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDSbbfOwCdud",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### a) f1-micro"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "XrMBVkDoCdui",
        "colab_type": "code",
        "outputId": "3f45043f-b37a-495e-db1d-f8aac3661f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "knn_micro = cv_best(knn_micro_estimator,train,train_labels,'micro')\n",
        "print('\\nConfusion Matrix\\n')\n",
        "knn_micro[2]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος GridSearchCV: 206.24187302589417 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.81      0.95      0.87      3673\n",
            "           h       0.86      0.58      0.70      2033\n",
            "\n",
            "   micro avg       0.82      0.82      0.82      5706\n",
            "   macro avg       0.83      0.77      0.78      5706\n",
            "weighted avg       0.83      0.82      0.81      5706\n",
            "\n",
            "Optimum f1- micro  is 0.8194882579740624\n",
            "\n",
            "Confusion Matrix\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3487</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>844</td>\n",
              "      <td>1189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g     h\n",
              "Class            \n",
              "g      3487   186\n",
              "h       844  1189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "VNePTHUAaev6",
        "colab_type": "code",
        "outputId": "cd0cc57c-9141-47c5-8b9e-39df07a75f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Optimum kNN f1-micro is\", knn_micro[0])\n",
        "\n",
        "start_time = time.time()\n",
        "knn_micro[0].fit(train,train_labels)\n",
        "preds = knn_micro[0].predict(test)\n",
        "knn_micro_time = (time.time() - start_time)\n",
        "print(\"\\n Συνολικός χρόνος fit και predict: %s seconds\" % knn_micro_time )"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimum kNN f1-micro is Pipeline(memory='tmp',\n",
            "     steps=[('selector', VarianceThreshold(threshold=0.02)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sampler', None), ('pca', PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
            "  svd_solver='auto', tol=0.0, whiten=False)), ('kNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
            "           metric_params=None, n_jobs=-1, n_neighbors=21, p=2,\n",
            "           weights='distance'))])\n",
            "\n",
            " Συνολικός χρόνος fit και predict: 0.7407608032226562 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WZ1l8EoBdlxm"
      },
      "cell_type": "markdown",
      "source": [
        "### b) f1-macro"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "outputId": "0438e6fc-1fb9-4155-a17b-1ccd1d8bea2c",
        "id": "YCqsCKcRd956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "knn_macro = cv_best(knn_macro_estimator,train,train_labels,'macro')\n",
        "print('\\nConfusion Matrix\\n')\n",
        "knn_macro[2]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος GridSearchCV: 208.48526620864868 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.84      0.87      0.86      3673\n",
            "           h       0.76      0.70      0.73      2033\n",
            "\n",
            "   micro avg       0.81      0.81      0.81      5706\n",
            "   macro avg       0.80      0.79      0.79      5706\n",
            "weighted avg       0.81      0.81      0.81      5706\n",
            "\n",
            "Optimum f1- macro  is 0.7931577580672573\n",
            "\n",
            "Confusion Matrix\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3212</td>\n",
              "      <td>461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>604</td>\n",
              "      <td>1429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g     h\n",
              "Class            \n",
              "g      3212   461\n",
              "h       604  1429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "802fde9b-4a7b-4efe-cecc-6691a6983dff",
        "id": "GnLcjsA9d96A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Optimum kNN f1-macro is\", knn_macro[0])\n",
        "\n",
        "start_time = time.time()\n",
        "knn_macro[0].fit(train,train_labels)\n",
        "preds = knn_macro[0].predict(test)\n",
        "knn_macro_time = (time.time() - start_time)\n",
        "print(\"\\n Συνολικός χρόνος fit και predict: %s seconds\" % knn_macro_time )"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimum kNN f1-macro is Pipeline(memory='tmp',\n",
            "     steps=[('selector', VarianceThreshold(threshold=0.02)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sampler', RandomOverSampler(random_state=None, ratio=None, return_indices=False,\n",
            "         sampling_strategy='auto')), ('pca', PCA(copy=True, iterated_power='auto', n_compon...an',\n",
            "           metric_params=None, n_jobs=-1, n_neighbors=17, p=2,\n",
            "           weights='distance'))])\n",
            "\n",
            " Συνολικός χρόνος fit και predict: 0.824897289276123 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LXGrxv75Cdv4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## MLP\n",
        "***"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Vh2dcmaMHhrT"
      },
      "cell_type": "markdown",
      "source": [
        "### Progressive Grid Search"
      ]
    },
    {
      "metadata": {
        "id": "eC1cuBrx-hLa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Παιρνουμε αρχικά το 1/8 του train set, etrain  γιατι αργεί πάρα πολύ!"
      ]
    },
    {
      "metadata": {
        "id": "xJxedowp-ejf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eighth = qtrain.shape[0] // 2\n",
        "\n",
        "etrain = qtrain[1:eighth]\n",
        "etrain_labels = qtrain_labels[1:eighth]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nG7aWkY71IWY"
      },
      "cell_type": "markdown",
      "source": [
        "Αρχικά βρίσκουμε τα ονόματα των παραμέτρων προς διερεύνηση  με την get_params().keys() . \n",
        "\n",
        "Για αυτές τις παραμέτρους ορίζουμε αρχικά τις παρακάτω μεταβλητές στα διαστήματα που αναγράφονται:\n",
        "\n",
        "- vthreshold = [0,0.02,0.04]\n",
        "- activation = ['identity', 'logistic', 'tanh', 'relu']\n",
        "- solver = ['lbfgs','sgd','adam']\n",
        "- max_iter = [100,200,300]\n",
        "- alpha = [1e-5, 1e-4, 1e-6]\n",
        "\n",
        "Οι εκτελέσεις σε ολοκληρο το train set είναι **αρκετά χρονοβόρες**.\n",
        "\n",
        "    steps=[('selector', VarianceThreshold(threshold=0.005)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sampler', None), ('pca', PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
        "    svd_solver='auto', tol=0.0, whiten=False)), ('MLP', MLPClassifier(activ...=True, solver='adam', tol=0.0001,\n",
        "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
        "       \n",
        "   (Το σύνολο των παραμέτρων που επιλέχθηκαν εμφανίστηκε με την get_params() σε κελί κώδικα παρακάτω και είχε alpha = 1e-05)    \n",
        "\n",
        "Συνολικός χρόνος GridSearchCV: 287.92994594573975 seconds\n",
        "\n",
        "Δοκιμάσαμε ξανά με πιο περιορισμένα εύρη παραμέτρων  και παρά τη (μικρή) μεταβολή των υπολοίπων παραμέτρων η παράμετρος max_iter παρέμενε ίση με 200 για όλα τα διαφορειτικά pipes και εκτελέσεις,δεν επιλέγει alpha = 1e-04, ούτε vthreshold = 0.04.\n",
        "\n",
        "Απορρίπτουμε λοιπόν και τις τιμες max_iter = 300, alpha=1e-04 και vthreshold = 0.04 και προχωράμε με μεταβλητές τα vthreshold και alpha για ολόκληρο το trainset, μετατοπίζοντας τα διαστήματα της αναζήτησης σε [0,0.01,0.02] και [1e-5,1e-6,1e-7] και κατόπιν νέων παρατηρήσεων σε [0,0.005,0.01] και [1e-04,1e-5,1e-6] αντίστοιχα. \n",
        "\n",
        "Tρέχουμε τώρα για το περιορισμένο εύρος των παραμέτρων που βρήκαμε μέσω prograssive grid search τη διαδικασία σε ολόκληρο το train set επιτυγχάνοντας ύστερα από αρκετό χρόνο τα βέλτιστα αποτελέσματα.\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "kDi-56P7Cdv8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(1,))\n",
        "\n",
        "vthreshold = [0,0.005,0.01]\n",
        "alpha = [1e-4,1e-5,1e-6]\n",
        "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
        "solver = ['lbfgs','sgd','adam']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "trusted": true,
        "id": "6Cf-nF1mjDBs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mlp_pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', ros),('pca',pca),('MLP', clf)], memory = 'tmp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HHBhx4iojDBv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mlp_params_grid = [dict(selector = [None], scaler = [None] , sampler = [None], pca = [None], MLP__alpha=alpha,MLP__activation = activation,MLP__solver = solver),\n",
        "                   dict(selector = [None], scaler = [None] ,pca = [None], MLP__alpha=alpha,MLP__activation = activation,MLP__solver = solver),\n",
        "                   dict(selector = [None], scaler = [None] ,pca__n_components = n_components, MLP__alpha=alpha,MLP__activation = activation,MLP__solver = solver),\n",
        "                   dict(selector = [None], pca__n_components = n_components, MLP__alpha=alpha,MLP__activation = activation,MLP__solver = solver),\n",
        "                   dict(selector__threshold=vthreshold,scaler = [None], sampler = [None],pca = [None], MLP__alpha=alpha,MLP__activation = activation,MLP__solver = solver),\n",
        "                   dict(selector__threshold=vthreshold, sampler = [None], pca__n_components = n_components,  MLP__alpha=alpha,MLP__activation = activation,MLP__solver = solver),\n",
        "                   dict(selector__threshold=vthreshold,pca__n_components = n_components,MLP__alpha=alpha,MLP__activation = activation,MLP__solver = solver)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oQyBxV4fjDBx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mlp_micro_estimator = GridSearchCV(mlp_pipe,param_grid=mlp_params_grid,cv=5, scoring='f1_micro', n_jobs=-1)\n",
        "mlp_macro_estimator = GridSearchCV(mlp_pipe,param_grid=mlp_params_grid,cv=5, scoring='f1_macro', n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6WO-Z8dXjDB0"
      },
      "cell_type": "markdown",
      "source": [
        "### a) f1-micro"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "outputId": "a2ad5411-25ce-4300-9735-c538fa754812",
        "id": "1XmEhO5FjDB2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "mlp_micro = cv_best(mlp_micro_estimator,train,train_labels,'micro')\n",
        "print('\\nConfusion Matrix\\n')\n",
        "mlp_micro[2]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος GridSearchCV: 2797.321962594986 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.87      0.75      0.81      3673\n",
            "           h       0.64      0.80      0.71      2033\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      5706\n",
            "   macro avg       0.76      0.78      0.76      5706\n",
            "weighted avg       0.79      0.77      0.77      5706\n",
            "\n",
            "Optimum f1- micro  is 0.7691903259726602\n",
            "\n",
            "Confusion Matrix\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>2770</td>\n",
              "      <td>903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>414</td>\n",
              "      <td>1619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g     h\n",
              "Class            \n",
              "g      2770   903\n",
              "h       414  1619"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "ad4c203e-352f-48c5-c425-0379b1f2c0c1",
        "id": "zO9ygCRnjDB8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Optimum MLP f1-micro is \", mlp_micro[0])\n",
        "\n",
        "start_time = time.time()\n",
        "mlp_micro[0].fit(train,train_labels)\n",
        "preds = mlp_micro[0].predict(test)\n",
        "mlp_micro_time = (time.time() - start_time)\n",
        "print(\"\\n Συνολικός χρόνος fit και predict: %s seconds\" % mlp_micro_time )"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimum MLP f1-micro is  Pipeline(memory='tmp',\n",
            "     steps=[('selector', None), ('scaler', None), ('sampler', RandomOverSampler(random_state=None, ratio=None, return_indices=False,\n",
            "         sampling_strategy='auto')), ('pca', PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
            "  svd_solver='auto', tol=0.0, whiten=False)), ('MLP', ...e=True, solver='sgd', tol=0.0001,\n",
            "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
            "\n",
            " Συνολικός χρόνος fit και predict: 1.054440975189209 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "huOomAU9TFHM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Προσθέσαμε την παρακάτω εντολή για να βρούμε ακριβώς τις παραμέτρους που δεν παρουσιάζονται λόγω μεγέθους στο προηγούμενο κελί κώδικα."
      ]
    },
    {
      "metadata": {
        "id": "b2nhNYTCS0nQ",
        "colab_type": "code",
        "outputId": "eebdcdd2-7e33-4548-c1a0-0a09afea2030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1088
        }
      },
      "cell_type": "code",
      "source": [
        "mlp_micro[0].get_params()\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MLP': MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
              "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "        hidden_layer_sizes=(1,), learning_rate='constant',\n",
              "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "        n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "        random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
              "        validation_fraction=0.1, verbose=False, warm_start=False),\n",
              " 'MLP__activation': 'relu',\n",
              " 'MLP__alpha': 1e-06,\n",
              " 'MLP__batch_size': 'auto',\n",
              " 'MLP__beta_1': 0.9,\n",
              " 'MLP__beta_2': 0.999,\n",
              " 'MLP__early_stopping': False,\n",
              " 'MLP__epsilon': 1e-08,\n",
              " 'MLP__hidden_layer_sizes': (1,),\n",
              " 'MLP__learning_rate': 'constant',\n",
              " 'MLP__learning_rate_init': 0.001,\n",
              " 'MLP__max_iter': 200,\n",
              " 'MLP__momentum': 0.9,\n",
              " 'MLP__n_iter_no_change': 10,\n",
              " 'MLP__nesterovs_momentum': True,\n",
              " 'MLP__power_t': 0.5,\n",
              " 'MLP__random_state': None,\n",
              " 'MLP__shuffle': True,\n",
              " 'MLP__solver': 'sgd',\n",
              " 'MLP__tol': 0.0001,\n",
              " 'MLP__validation_fraction': 0.1,\n",
              " 'MLP__verbose': False,\n",
              " 'MLP__warm_start': False,\n",
              " 'memory': 'tmp',\n",
              " 'pca': PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
              "   svd_solver='auto', tol=0.0, whiten=False),\n",
              " 'pca__copy': True,\n",
              " 'pca__iterated_power': 'auto',\n",
              " 'pca__n_components': 8,\n",
              " 'pca__random_state': None,\n",
              " 'pca__svd_solver': 'auto',\n",
              " 'pca__tol': 0.0,\n",
              " 'pca__whiten': False,\n",
              " 'sampler': RandomOverSampler(random_state=None, ratio=None, return_indices=False,\n",
              "          sampling_strategy='auto'),\n",
              " 'sampler__random_state': None,\n",
              " 'sampler__ratio': None,\n",
              " 'sampler__return_indices': False,\n",
              " 'sampler__sampling_strategy': 'auto',\n",
              " 'scaler': None,\n",
              " 'selector': None,\n",
              " 'steps': [('selector', None),\n",
              "  ('scaler', None),\n",
              "  ('sampler',\n",
              "   RandomOverSampler(random_state=None, ratio=None, return_indices=False,\n",
              "            sampling_strategy='auto')),\n",
              "  ('pca',\n",
              "   PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
              "     svd_solver='auto', tol=0.0, whiten=False)),\n",
              "  ('MLP',\n",
              "   MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
              "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "          hidden_layer_sizes=(1,), learning_rate='constant',\n",
              "          learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "          n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "          random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
              "          validation_fraction=0.1, verbose=False, warm_start=False))]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ptRThxF6jDCN"
      },
      "cell_type": "markdown",
      "source": [
        "### b) f1-macro"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "outputId": "f1efa2e1-6256-48f4-a9d1-18ed86622f31",
        "id": "y_mcC2q2jDCP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "mlp_macro = cv_best(mlp_macro_estimator,train,train_labels,'macro')\n",
        "print('\\nConfusion Matrix\\n')\n",
        "mlp_macro[2]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος GridSearchCV: 2699.2427134513855 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.83      0.87      0.85      3673\n",
            "           h       0.74      0.69      0.71      2033\n",
            "\n",
            "   micro avg       0.80      0.80      0.80      5706\n",
            "   macro avg       0.79      0.78      0.78      5706\n",
            "weighted avg       0.80      0.80      0.80      5706\n",
            "\n",
            "Optimum f1- macro  is 0.7807278017445385\n",
            "\n",
            "Confusion Matrix\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>3180</td>\n",
              "      <td>493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>636</td>\n",
              "      <td>1397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g     h\n",
              "Class            \n",
              "g      3180   493\n",
              "h       636  1397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "3c20e619-ef44-4f36-f695-411e8f3a68ee",
        "id": "P08IICdFjDCZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Optimum MLP f1-macro is \", mlp_macro[0])\n",
        "\n",
        "start_time = time.time()\n",
        "mlp_macro[0].fit(train,train_labels)\n",
        "preds = mlp_macro[0].predict(test)\n",
        "mlp_macro_time = (time.time() - start_time)\n",
        "print(\"\\n Συνολικός χρόνος fit και predict: %s seconds\" % mlp_macro_time )"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimum MLP f1-macro is  Pipeline(memory='tmp',\n",
            "     steps=[('selector', None), ('scaler', None), ('sampler', RandomOverSampler(random_state=None, ratio=None, return_indices=False,\n",
            "         sampling_strategy='auto')), ('pca', PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
            "  svd_solver='auto', tol=0.0, whiten=False)), ('MLP', ...e=True, solver='sgd', tol=0.0001,\n",
            "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
            "\n",
            " Συνολικός χρόνος fit και predict: 1.1243007183074951 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "52e74ee6-e0ce-4870-b70f-d3f99d0b0c39",
        "id": "5cF3SFmzfK5o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1088
        }
      },
      "cell_type": "code",
      "source": [
        "mlp_macro[0].get_params()\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MLP': MLPClassifier(activation='tanh', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
              "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "        hidden_layer_sizes=(1,), learning_rate='constant',\n",
              "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "        n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "        random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
              "        validation_fraction=0.1, verbose=False, warm_start=False),\n",
              " 'MLP__activation': 'tanh',\n",
              " 'MLP__alpha': 1e-06,\n",
              " 'MLP__batch_size': 'auto',\n",
              " 'MLP__beta_1': 0.9,\n",
              " 'MLP__beta_2': 0.999,\n",
              " 'MLP__early_stopping': False,\n",
              " 'MLP__epsilon': 1e-08,\n",
              " 'MLP__hidden_layer_sizes': (1,),\n",
              " 'MLP__learning_rate': 'constant',\n",
              " 'MLP__learning_rate_init': 0.001,\n",
              " 'MLP__max_iter': 200,\n",
              " 'MLP__momentum': 0.9,\n",
              " 'MLP__n_iter_no_change': 10,\n",
              " 'MLP__nesterovs_momentum': True,\n",
              " 'MLP__power_t': 0.5,\n",
              " 'MLP__random_state': None,\n",
              " 'MLP__shuffle': True,\n",
              " 'MLP__solver': 'sgd',\n",
              " 'MLP__tol': 0.0001,\n",
              " 'MLP__validation_fraction': 0.1,\n",
              " 'MLP__verbose': False,\n",
              " 'MLP__warm_start': False,\n",
              " 'memory': 'tmp',\n",
              " 'pca': PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
              "   svd_solver='auto', tol=0.0, whiten=False),\n",
              " 'pca__copy': True,\n",
              " 'pca__iterated_power': 'auto',\n",
              " 'pca__n_components': 8,\n",
              " 'pca__random_state': None,\n",
              " 'pca__svd_solver': 'auto',\n",
              " 'pca__tol': 0.0,\n",
              " 'pca__whiten': False,\n",
              " 'sampler': RandomOverSampler(random_state=None, ratio=None, return_indices=False,\n",
              "          sampling_strategy='auto'),\n",
              " 'sampler__random_state': None,\n",
              " 'sampler__ratio': None,\n",
              " 'sampler__return_indices': False,\n",
              " 'sampler__sampling_strategy': 'auto',\n",
              " 'scaler': None,\n",
              " 'selector': None,\n",
              " 'steps': [('selector', None),\n",
              "  ('scaler', None),\n",
              "  ('sampler',\n",
              "   RandomOverSampler(random_state=None, ratio=None, return_indices=False,\n",
              "            sampling_strategy='auto')),\n",
              "  ('pca',\n",
              "   PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
              "     svd_solver='auto', tol=0.0, whiten=False)),\n",
              "  ('MLP',\n",
              "   MLPClassifier(activation='tanh', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
              "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "          hidden_layer_sizes=(1,), learning_rate='constant',\n",
              "          learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "          n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "          random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
              "          validation_fraction=0.1, verbose=False, warm_start=False))]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "SdsSLlDNyVWA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Δ2. Χρόνοι εκτέλεσης"
      ]
    },
    {
      "metadata": {
        "id": "9njk-OVGy72L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Οι χρόνοι που χρειάστηκαν για το fit σε κάθε train set και predict στο test set τυπώνονται στο Δ1 στο τέλος κάθε ξεχωριστού GridSearchCV.\n",
        "Συγκεντρωμένοι, παρουσιάζονται στον παρακάτω πίνακα:\n",
        "\n",
        "|Classifier/Metric|f1-micro time (sec)|f1-macro time (sec)|\n",
        "|-|-|-|\n",
        "|Gaussian Naive Bayes   |29.160797357559204|20.095083236694336|\n",
        "|k-Nearest Neighbours    |206.24187302589417|208.48526620864868|\n",
        "|Multi-layer Perceptron    |2797.321962594986|2699.2427134513855|\n",
        " \n",
        "\n",
        "Οι χρόνοι του fit και predict στον επιλεγμένο βέλτιστο ταξινομητή κάθε φορά τυπώνονται παρακάτω:"
      ]
    },
    {
      "metadata": {
        "id": "NhiC6tsgwhZU",
        "colab_type": "code",
        "outputId": "b02c0017-7aa5-42f2-c911-dd5347f405d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "times = np.array([ [gnb_micro_time ,gnb_macro_time],\n",
        "                   [knn_micro_time ,knn_macro_time],\n",
        "                   [mlp_micro_time ,mlp_macro_time] ])\n",
        "\n",
        "cols = ['f1-micro','f1-macro']\n",
        "\n",
        "df = pd.DataFrame(times,columns = cols)\n",
        "df['Classifier'] = ['GNB','kNN','MLP']\n",
        "df.set_index('Classifier',inplace=True)\n",
        "\n",
        "print('Χρόνοι τελικών fit-predict (sec) ')\n",
        "df\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Χρόνοι τελικών fit-predict (sec) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1-micro</th>\n",
              "      <th>f1-macro</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GNB</th>\n",
              "      <td>0.220821</td>\n",
              "      <td>0.307679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kNN</th>\n",
              "      <td>0.740761</td>\n",
              "      <td>0.824897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>1.054441</td>\n",
              "      <td>1.124301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            f1-micro  f1-macro\n",
              "Classifier                    \n",
              "GNB         0.220821  0.307679\n",
              "kNN         0.740761  0.824897\n",
              "MLP         1.054441  1.124301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "G1HpKQ3Yi15q"
      },
      "cell_type": "markdown",
      "source": [
        "## ***Δ3. Bar Plot***"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f3a9ccec-89b7-4699-cda3-cf2afda36cb7",
        "id": "IJDFnfMvqIlp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "x_axis = ['F1 Micro','F1 Macro']\n",
        "\n",
        "ind = np.arange(len(x_axis))\n",
        "\n",
        "plt.xticks(ind,x_axis)\n",
        "\n",
        "plt.title(\"Classifier Metrics\")\n",
        "plt.bar(ind-0.3,dummy_metrics_uniform,width=0.1,label=\"Uniform\") \n",
        "plt.bar(ind-0.2,dummy_metrics_g,width=0.1,label=\"g Const\") \n",
        "plt.bar(ind-0.1,dummy_metrics_h,width=0.1,label=\"h Const\") \n",
        "plt.bar(ind,dummy_metrics_stratified,width=0.1,label=\"Stratified\") \n",
        "plt.bar(ind+0.1,[gnb_micro[1],gnb_macro[1]],width=0.1,label=\"GNB\")\n",
        "plt.bar(ind+0.2,[knn_micro[1],knn_macro[1]],width=0.1,label=\"kNN\") \n",
        "plt.bar(ind+0.3,[mlp_micro[1],mlp_macro[1]],width=0.1,label=\"MLP\")\n",
        "plt.legend()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f52bfff4828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f52bfff4080>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ECOIQvcIE3Qw"
      },
      "cell_type": "markdown",
      "source": [
        "## Δ4. Μεταβολή Επίδοσης"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "7a9ba181-53d3-436e-a9e2-a2fb0a96064a",
        "id": "dAB5kBRDq27Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "dscore = np.array([[gnb_micro[1] - gnb_metrics[0] ,gnb_macro[1] - gnb_metrics[1]] ,\n",
        "                   [knn_micro[1] - knn_metrics[0] ,knn_macro[1] - knn_metrics[1]],\n",
        "                   [mlp_micro[1] - mlp_metrics[0] ,mlp_macro[1] - mlp_metrics[1]] ])\n",
        "\n",
        "cols = ['f1-micro','f1-macro']\n",
        "\n",
        "df = pd.DataFrame(dscore*100,columns = cols)\n",
        "df['Classifier'] = ['GNB','kNN','MLP']\n",
        "df.set_index('Classifier',inplace=True)\n",
        "\n",
        "print('Βελτίωση Επίδοσης Ταξινομητών επί τοις εκατό (%) ')\n",
        "df"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Βελτίωση Επίδοσης Ταξινομητών επί τοις εκατό (%) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1-micro</th>\n",
              "      <th>f1-macro</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GNB</th>\n",
              "      <td>3.259727</td>\n",
              "      <td>5.814840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kNN</th>\n",
              "      <td>1.910270</td>\n",
              "      <td>2.692547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>11.987382</td>\n",
              "      <td>37.005081</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             f1-micro   f1-macro\n",
              "Classifier                      \n",
              "GNB          3.259727   5.814840\n",
              "kNN          1.910270   2.692547\n",
              "MLP         11.987382  37.005081"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6g_I9aVIGD5N"
      },
      "cell_type": "markdown",
      "source": [
        "## Δ5. Σχολιασμός Αποτελεσμάτων"
      ]
    },
    {
      "metadata": {
        "id": "aVkjcrtpGUbu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Όπως βλέπουμε από τις μετρικές των ταξινομητών και το Bar Plot τους, η βέλτιστη επίδοση προκύπτει και για τις δύο μετρικές από τον kNN μετασχηματιστή. Σημειωτέον πως οι τιμές αυτές προκύπτουν για **MLP με ένα μόνο επίπεδο κρυφών νευρώνων** όπως αναγράφεται στην εκφώνηση της άσκησης. Δοκιμάζοντας να βάλουμε και τον αριθμό αυτό ως παράμετρο στην αναζήτηση πήραμε αποτελέσματα έως και 84% σε f1-micro score για 100 επίπεδα, μετρήσεις οι οποίες ωστόσο δεν συμπεριλαμβάνονται διότι δεν ζητούνται. \n",
        "\n",
        "Παρατηρούμε πως μεγαλύτερη βελτίωση επιδέχθηκε ο MLP Classifier, ο οποίος ωστόσο είχε δώσει εξ αρχής μικρά score και γι αυτό είχε μεγάλο περιθώριο βελτίωσης. Παρατηρούμε ακόμη πως και ο GNB βελτιώνεται ικανοποιητικά μέσω Grid Search Cross Validation, καθώς και ο kNN αν και σε μικρότερο βαθμό, έχοντας δώσει ωστόσο αρκετά καλά αποτελέσματα από το Μέρος Γ.\n",
        "\n",
        "Ως προς το χρόνο εκτέλεσης βλέπουμε πως ο kNN χρειάζεται για το grid search 10-πλάσιο χρόνο από τον GNB έχοντας ωστόσο και περισσότερα ορίσματα προς διερεύνηση. \n",
        "To Μultilayer Perceptron είναι μακράν το πιο χρονοβόρο με χρόνο 100-πλάσιο από το χρόνο του GNB και 10-πλάσιο του kNN. Αυτό είναι ωστόσο εν μέρει και επειδή διαλέξαμε να παρουσιάσουμε τα αποτελέσματα για όλο το εύρος των μη-αριθμητικών υπερπαραμέτρων, όπως ακριβώς τα υπολογίσαμε. Μπορούσαμε για να παρουσιάσουμε καλύτερο χρόνο και να πειραματιστούμε περαιτέρω με τις αριθμητικές παραμέτρους, να κρατήσουμε σταθερές τις μη-αριθμητικές που μας έδωσε αυτή η GridSearchCV.     \n",
        "Η αναλογία ωστόσο των χρόνων των ταξινομητών παραμένει ποιοτικά η ίδια, όπως παρατηρούμε και από τους χρόνους του τελικου fit για τον επιλεγμένο Classifier με τις υπερπαραμέτρους του.\n",
        "\n",
        "Όπως και στο Γ, το GNB έχει χαμηλό f1-score για την κλάση h και υψηλό recall για την κλάση g. Ο kNN έχει 95% recall για την επικρατούσα κλάση και υψηλά (όπως φαίνεται και από το Bar Plot) f1 metrics, ενώ τέλος για το MLP παρατηρούμε την εντυπωσιακή βελτίωση σε σχέση με τις μετρικές του Μέρους Γ."
      ]
    }
  ]
}